{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from typing import Callable\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка базы данных MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path):\n",
    "    with open(path, mode='rb') as f:\n",
    "        training_data, _, test_data = pickle.load(f, encoding='bytes')\n",
    "        return dict(\n",
    "            training_images = training_data[0],\n",
    "            training_labels = training_data[1],\n",
    "            test_images = test_data[0],\n",
    "            test_labels = test_data[1]\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рисование цифры MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_mnist_digit(mnist, example):\n",
    "    label = mnist['training_labels'][example]\n",
    "    plt.title('Example: %d, label: %d' % (example, label))\n",
    "    plt.imshow(np.array(mnist['training_images'][7]).reshape((28, 28)), cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD():\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def init_network(self, network):\n",
    "        self.network = network\n",
    "    \n",
    "    def update(self, grad_w, grad_b, batch, expected):\n",
    "        for i in range(len(self.network.layers) - 1, 0, -1):\n",
    "            self.network.weights[i] -= self.learning_rate * grad_w[i]\n",
    "            self.network.biases[i] -= self.learning_rate * grad_b[i]\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'SGD'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сопряжённые градиенты (метод Флетчера-Ривза FR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConjugateGradientFR():\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def init_network(self, network):\n",
    "        self.network = network\n",
    "        self.prev_grad_w = None\n",
    "        self.previous_d = None\n",
    "\n",
    "    def update(self, grad_w, grad_b, batch, expected):\n",
    "        if self.previous_d is None:\n",
    "            self.previous_d = [-grad_w[i] for i in range(1, len(self.network.layers))]\n",
    "        else:\n",
    "            beta = [np.zeros((grad_w[i].shape[0], 1)) for i in range(1, len(self.network.layers))]\n",
    "            for i in range(1, len(self.network.layers)):\n",
    "                numerator = np.diagonal(np.dot(grad_w[i], np.transpose(grad_w[i])))\n",
    "                denominator = np.diagonal(np.dot(self.prev_grad_w[i], np.transpose(self.prev_grad_w[i])))\n",
    "                beta[i - 1] = numerator / (denominator + 1e-100)\n",
    "                beta[i - 1] = np.where(beta[i - 1] < 1, beta[i - 1], 0)\n",
    "                for j in range(beta[i - 1].shape[0]):\n",
    "                    self.previous_d[i - 1][j] = -grad_w[i][j] + beta[i - 1][j] * self.previous_d[i - 1][j]\n",
    "            # self.previous_d = [-grad_w[i] + np.dot(beta[i - 1], self.previous_d[i - 1]) for i in range(1, len(self.network.layers))]\n",
    "        for i in range(1, len(self.network.layers)):\n",
    "            self.network.weights[i] += self.learning_rate * self.previous_d[i - 1]\n",
    "            self.network.biases[i] -= self.learning_rate * grad_b[i]\n",
    "        self.prev_grad_w = grad_w\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Conjugate Gradient FR'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод Бройдена-Флетчера-Гольдфарба-Шенно (BFGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFGS():\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def init_network(self, network):\n",
    "        self.network = network\n",
    "        self.H = [None] + [np.eye(self.network.weights[i].shape[0]) for i in range(1, len(self.network.layers))]\n",
    "        self.prev_grad_w = [None] + [np.zeros_like(self.network.weights[i]) for i in range(1, len(self.network.layers))]\n",
    "        self.prev_weights = [None] + [np.zeros_like(self.network.weights[i]) for i in range(1, len(self.network.layers))]\n",
    "\n",
    "    def update(self, grad_w, grad_b):\n",
    "        for i in range(1, len(self.network.layers)):\n",
    "            delta_w = -self.learning_rate * np.dot(self.H[i], grad_w[i])\n",
    "            delta_b = -self.learning_rate * grad_b[i]\n",
    "            self.network.weights[i] += delta_w\n",
    "            self.network.biases[i] += delta_b\n",
    "\n",
    "            delta_grad_w_i = grad_w[i] - self.prev_grad_w[i]\n",
    "            delta_weight_i = self.network.weights[i] - self.prev_weights[i]\n",
    "            \n",
    "            rho = 1.0 / (np.dot(delta_weight_i, np.transpose(delta_grad_w_i)) + 1e-100)\n",
    "            rho = np.where((rho > 0) & (rho < 1) , rho, 0)\n",
    "            self.H[i] = (np.eye(self.network.weights[i].shape[0]) - \\\n",
    "                        rho * np.dot(delta_weight_i, np.transpose(delta_grad_w_i))) * self.H[i] * \\\n",
    "                        (np.eye(self.network.weights[i].shape[0]) - \\\n",
    "                        rho * np.dot(delta_grad_w_i, np.transpose(delta_weight_i))) + \\\n",
    "                        rho * np.dot(delta_weight_i, np.transpose(delta_weight_i))\n",
    "        self.prev_grad_w = grad_w\n",
    "        self.prev_weights = deepcopy(self.network.weights)\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'BFGS'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ускоренный градиент Нестерова (Nesterov accelerated gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAG():\n",
    "    def __init__(self, learning_rate, gamma):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def init_network(self, network):\n",
    "        self.network = network\n",
    "        self.vt_w = [None] + [np.zeros_like(self.network.weights[i]) for i in range(1, len(self.network.weights))]\n",
    "        self.vt_b = [None] + [np.zeros_like(self.network.biases[i]) for i in range(1, len(self.network.biases))]\n",
    "        \n",
    "    def update(self, grad_w, grad_b, batch, expected):\n",
    "        network_predicted = deepcopy(self.network)\n",
    "        for i in range(1, len(self.network.layers)):\n",
    "            network_predicted.weights[i] -= self.gamma * self.vt_w[i]\n",
    "            network_predicted.biases[i] -= self.gamma * self.vt_b[i]\n",
    "\n",
    "        weighted_inputs, predicted = network_predicted.feedforward(np.transpose(batch))\n",
    "        errors = network_predicted.backpropogate_error(weighted_inputs, predicted[-1], expected)\n",
    "        grad_w_predicted = [None for _ in range(len(network_predicted.layers))]\n",
    "        grad_b_predicted = [None for _ in range(len(network_predicted.layers))]\n",
    "        for i in range(len(network_predicted.layers) - 1, 0, -1):\n",
    "            grad_w_predicted[i] = np.dot(errors[i], np.transpose(predicted[i - 1])) / batch.shape[0]\n",
    "            grad_b_predicted[i] = errors[i].sum(axis=1) / batch.shape[0]\n",
    "        \n",
    "        for i in range(1, len(self.network.layers)):\n",
    "            self.vt_w[i] = self.gamma * self.vt_w[i] + self.learning_rate * grad_w_predicted[i]\n",
    "            self.vt_b[i] = self.gamma * self.vt_b[i] + self.learning_rate * grad_b_predicted[i] \n",
    "            self.network.weights[i] -= self.vt_w[i]\n",
    "            self.network.biases[i] -= self.vt_b[i]\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'NAG'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Адаптивный градиент (Adagrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adagrad():\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def init_network(self, network):\n",
    "        self.network = network\n",
    "        self.G_w = [None] + [np.zeros_like(self.network.weights[i]) for i in range(1, len(self.network.weights))]\n",
    "        self.G_b = [None] + [np.zeros_like(self.network.biases[i]) for i in range(1, len(self.network.biases))]\n",
    "        \n",
    "    def update(self, grad_w, grad_b, batch, expected):\n",
    "        for i in range(1, len(self.network.layers)):\n",
    "            self.G_w[i] += grad_w[i] ** 2\n",
    "            self.G_b[i] += grad_b[i] ** 2\n",
    "            adapted_learning_rate_w = self.learning_rate / np.sqrt(self.G_w[i] + 1e-8)\n",
    "            adapted_learning_rate_b = self.learning_rate / np.sqrt(self.G_b[i] + 1e-8)\n",
    "            self.network.weights[i] -= adapted_learning_rate_w * grad_w[i]\n",
    "            self.network.biases[i] -= adapted_learning_rate_b * grad_b[i]\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Adagrad'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод адаптивной оценки моментов (Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam():\n",
    "    def __init__(self, learning_rate, beta1, beta2):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "\n",
    "    def init_network(self, network):\n",
    "        self.network = network\n",
    "        self.m_w = [None] + [np.zeros_like(self.network.weights[i]) for i in range(1, len(self.network.weights))]\n",
    "        self.v_w = [None] + [np.zeros_like(self.network.weights[i]) for i in range(1, len(self.network.weights))]\n",
    "        self.m_b = [None] + [np.zeros_like(self.network.biases[i]) for i in range(1, len(self.network.biases))]\n",
    "        self.v_b = [None] + [np.zeros_like(self.network.biases[i]) for i in range(1, len(self.network.biases))]\n",
    "        self.epoch = 1\n",
    "        \n",
    "    def update(self, grad_w, grad_b, batch, expected):\n",
    "        for i in range(1, len(self.network.layers)):\n",
    "            self.m_w[i] = self.beta1 * self.m_w[i] + (1 - self.beta1) * grad_w[i]\n",
    "            self.m_b[i] = self.beta1 * self.m_b[i] + (1 - self.beta1) * grad_b[i]\n",
    "            self.v_w[i] = self.beta2 * self.v_w[i] + (1 - self.beta2) * grad_w[i] ** 2\n",
    "            self.v_b[i] = self.beta2 * self.v_b[i] + (1 - self.beta2) * grad_b[i] ** 2\n",
    "\n",
    "            m_w_i = self.m_w[i] / (1 - self.beta1 ** self.epoch)\n",
    "            m_b_i = self.m_b[i] / (1 - self.beta1 ** self.epoch)\n",
    "            v_w_i = self.v_w[i] / (1 - self.beta2 ** self.epoch)\n",
    "            v_b_i = self.v_b[i] / (1 - self.beta2 ** self.epoch)\n",
    "            \n",
    "            self.network.weights[i] -= self.learning_rate * m_w_i / (np.sqrt(v_w_i) + 1e-8)\n",
    "            self.network.biases[i] -= self.learning_rate * m_b_i / (np.sqrt(v_b_i) + 1e-8)\n",
    "        self.epoch += 1\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Adam'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Средняя квадратичная ошибка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError():\n",
    "    # средняя квадратичная ошибка\n",
    "    @staticmethod\n",
    "    def calculate(expected, predicted):\n",
    "        return np.mean((expected - predicted) ** 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Категориальная перекрёстная энтропия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategorialCrossEntropy():\n",
    "    # категориальная перекрёстная энтропия\n",
    "    @staticmethod\n",
    "    def calculate(expected, predicted):\n",
    "        return -np.sum(expected * np.log(predicted + 1e-100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дивергенция Кульбака-Лейблера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDivergence():\n",
    "    # дивергенция Кульбака-Лейблера\n",
    "    @staticmethod\n",
    "    def calculate(expected, predicted):\n",
    "        return np.sum(expected * np.log((expected + 1e-100) / (predicted + 1e-100)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Класс для представления многослойного персептрона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, layers, optimizer):\n",
    "        # layers-- это кортеж, каждый элемент которого\n",
    "        # представляет количество нейронов в соответствующем слое \n",
    "        self.layers = layers\n",
    "        self.weights = [None]\n",
    "        self.biases = [None]\n",
    "        # инициализация весов и bias-ов в каждом слое\n",
    "        # для входного слоя веса и bias-ы не нужны\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.weights.append(np.random.normal(0.0, np.sqrt(2.0 / (self.layers[i - 1] + self.layers[i])), size=(self.layers[i], self.layers[i - 1])))\n",
    "            self.biases.append(np.random.normal(0.0,  np.sqrt(2.0 / (self.layers[i - 1] + self.layers[i])), size=self.layers[i]))\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizer.init_network(self)\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        #return 1 / (1 + np.exp(np.clip(-x, a_min=-100, a_max=100)))\n",
    "        return np.vectorize(lambda x: x if x >= 0 else 0)(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        return np.exp(x - max(x)) / np.sum(np.exp(x - max(x)))\n",
    "    \n",
    "    def activate(self, x, activation):\n",
    "        if activation not in ('relu', 'softmax'):\n",
    "            raise Exception('activation should be \"relu\" or \"softmax\"')\n",
    "        if activation == 'relu':\n",
    "            return self.relu(x)\n",
    "        return np.apply_along_axis(self.softmax, 0, x)\n",
    "    \n",
    "    def activation_func_derivative(self, x, activation):\n",
    "        if activation not in ('relu', 'softmax'):\n",
    "            raise Exception('activation should be \"relu\" or \"softmax\"')\n",
    "        if activation == 'relu':\n",
    "             #return self.activate(x, 'relu') * (1 - self.activate(x, 'relu'))\n",
    "            return np.vectorize(lambda x: 1 if x >= 0 else 0)(x)\n",
    "        return self.activate(x, 'softmax') * (1 - self.activate(x, 'softmax'))\n",
    "    \n",
    "    def feedforward(self, input):\n",
    "        weighted_inputs, outputs = [None], [input]\n",
    "        for i in range(1, len(self.layers)):\n",
    "            weighted_input = np.dot(self.weights[i], outputs[i - 1]) + self.biases[i].reshape(self.layers[i], 1)\n",
    "            output = self.activate(weighted_input, 'relu') if i != len(self.layers) - 1 else self.activate(weighted_input, 'softmax')\n",
    "            weighted_inputs.append(weighted_input)\n",
    "            outputs.append(output)\n",
    "        return (weighted_inputs, outputs)\n",
    "    \n",
    "    def train(self, training_data, test_data, epochs, batch_size, loss_func, is_loss_funcs_plot_needed):\n",
    "        self.loss_func = loss_func\n",
    "        training_data = list(zip(training_data['training_images'], training_data['training_expected']))\n",
    "        x, y = [], []\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            loss = 0\n",
    "            np.random.shuffle(training_data)\n",
    "            training_images, training_expected = zip(*training_data)\n",
    "            training_images, training_expected = np.array(training_images), np.array(training_expected)\n",
    "            n = 0\n",
    "            for i in range(0, training_images.shape[0], batch_size):\n",
    "                batch = training_images[i: i + batch_size]\n",
    "                expected = np.transpose(training_expected[i: i + batch_size])\n",
    "                weighted_inputs, predicted = self.feedforward(np.transpose(batch))\n",
    "                errors = self.backpropogate_error(weighted_inputs, predicted[-1], expected)\n",
    "                grad_w, grad_b = [None for _ in range(len(self.layers))], [None for _ in range(len(self.layers))]\n",
    "                for i in range(len(self.layers) - 1, 0, -1):\n",
    "                    grad_w[i] = np.dot(errors[i], np.transpose(predicted[i - 1])) / batch_size\n",
    "                    grad_b[i] = errors[i].sum(axis=1) / batch_size\n",
    "                self.optimizer.update(grad_w, grad_b, batch, expected)\n",
    "                loss += loss_func.calculate(expected=expected, predicted=predicted[-1]) / batch_size\n",
    "                n += 1\n",
    "            loss /= n\n",
    "            score, _ = self.predict(test_data=test_data)\n",
    "            # print(f'Epoch {epoch}\\{epochs}\\nloss: {loss: .2f}, accuracy: {score: .2f}%')\n",
    "            x.append(epoch)\n",
    "            y.append(loss)\n",
    "        self.loss_func_values = y\n",
    "        if is_loss_funcs_plot_needed:\n",
    "            self.plot_loss_funcs(x, y)\n",
    "\n",
    "    def backpropogate_error(self, weighted_inputs, predicted_data, expected_data):\n",
    "        errors = [None for _ in self.layers]\n",
    "        # errors[-1] = 2 * (predicted_data - expected_data) / predicted_data.shape[1] #* self.activation_func_derivative(weighted_inputs[-1], 'relu')\n",
    "        errors[-1] = predicted_data - expected_data\n",
    "        for i in range(len(self.layers) - 2, 0, -1):\n",
    "            errors[i] = np.dot(np.transpose(self.weights[i + 1]), errors[i + 1]) * \\\n",
    "                  self.activation_func_derivative(weighted_inputs[i], 'relu')\n",
    "        return errors\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        score, loss, n = 0, 0, 0\n",
    "        for test_image, test_expected in zip(test_data['test_images'], test_data['test_expected']):\n",
    "            predicted = self.feedforward(test_image.reshape(784, 1))[1][-1]\n",
    "            predicted_label = np.argmax(predicted)\n",
    "            expected_label = np.argmax(test_expected)\n",
    "            score = score + 1 if predicted_label == expected_label else score\n",
    "            loss += self.loss_func.calculate(expected=test_expected, predicted=predicted)\n",
    "            n += 1\n",
    "        return score / n * 100, loss / test_data['test_images'].shape[0]\n",
    "    \n",
    "    def plot_loss_funcs(self, x, y):\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.plot(x, y, label='cross_entropy_loss', c='red')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "            \n",
    "    def get_loss_values(self):\n",
    "        return self.loss_func_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование\n",
    "### Рисование цифры MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = load_mnist('mnist.pkl')\n",
    "draw_mnist_digit(mnist, example=7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_expected = np.array([[1.0 if i == label else 0 for i in range(10)] for label in mnist['training_labels']])\n",
    "training_data = dict(\n",
    "    training_images=mnist['training_images'],\n",
    "    training_expected=training_expected\n",
    ")\n",
    "test_expected = np.array([[1.0 if i == label else 0 for i in range(10)] for label in mnist['test_labels']])\n",
    "test_data = dict(\n",
    "    test_images=mnist['test_images'],\n",
    "    test_expected=test_expected\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение и тестирование многослойного персептрона\n",
    "В качестве функции активации используется `ReLu`, а на последнем слое - `Softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      3\u001b[0m perceptron \u001b[39m=\u001b[39m Perceptron(layers\u001b[39m=\u001b[39m(\u001b[39m784\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m10\u001b[39m), optimizer\u001b[39m=\u001b[39mSGD(\u001b[39m0.01\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m perceptron\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      5\u001b[0m     training_data\u001b[39m=\u001b[39;49mtraining_data,\n\u001b[1;32m      6\u001b[0m     test_data\u001b[39m=\u001b[39;49mtest_data,\n\u001b[1;32m      7\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m      8\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m70\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     loss_func\u001b[39m=\u001b[39;49mCategorialCrossEntropy(),\n\u001b[1;32m     10\u001b[0m     is_loss_funcs_plot_needed\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m score, _ \u001b[39m=\u001b[39m perceptron\u001b[39m.\u001b[39mpredict(test_data\u001b[39m=\u001b[39mtest_data)\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAccuracy of guessed numbers: \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m:\u001b[39;00m\u001b[39m .2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 72\u001b[0m, in \u001b[0;36mPerceptron.train\u001b[0;34m(self, training_data, test_data, epochs, batch_size, loss_func, is_loss_funcs_plot_needed)\u001b[0m\n\u001b[1;32m     70\u001b[0m     n \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     71\u001b[0m loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m n\n\u001b[0;32m---> 72\u001b[0m score, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(test_data\u001b[39m=\u001b[39;49mtest_data)\n\u001b[1;32m     73\u001b[0m \u001b[39m# print(f'Epoch {epoch}\\{epochs}\\nloss: {loss: .2f}, accuracy: {score: .2f}%')\u001b[39;00m\n\u001b[1;32m     74\u001b[0m x\u001b[39m.\u001b[39mappend(epoch)\n",
      "Cell \u001b[0;32mIn[16], line 92\u001b[0m, in \u001b[0;36mPerceptron.predict\u001b[0;34m(self, test_data)\u001b[0m\n\u001b[1;32m     90\u001b[0m score, loss, n \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[39mfor\u001b[39;00m test_image, test_expected \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(test_data[\u001b[39m'\u001b[39m\u001b[39mtest_images\u001b[39m\u001b[39m'\u001b[39m], test_data[\u001b[39m'\u001b[39m\u001b[39mtest_expected\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m---> 92\u001b[0m     predicted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeedforward(test_image\u001b[39m.\u001b[39;49mreshape(\u001b[39m784\u001b[39;49m, \u001b[39m1\u001b[39;49m))[\u001b[39m1\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     93\u001b[0m     predicted_label \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(predicted)\n\u001b[1;32m     94\u001b[0m     expected_label \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(test_expected)\n",
      "Cell \u001b[0;32mIn[16], line 44\u001b[0m, in \u001b[0;36mPerceptron.feedforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers)):\n\u001b[1;32m     43\u001b[0m     weighted_input \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[i], outputs[i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbiases[i]\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[i], \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivate(weighted_input, \u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivate(weighted_input, \u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m     weighted_inputs\u001b[39m.\u001b[39mappend(weighted_input)\n\u001b[1;32m     46\u001b[0m     outputs\u001b[39m.\u001b[39mappend(output)\n",
      "Cell \u001b[0;32mIn[16], line 29\u001b[0m, in \u001b[0;36mPerceptron.activate\u001b[0;34m(self, x, activation)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mactivation should be \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m activation \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu(x)\n\u001b[1;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mapply_along_axis(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax, \u001b[39m0\u001b[39m, x)\n",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m, in \u001b[0;36mPerceptron.relu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrelu\u001b[39m(x):\n\u001b[1;32m     18\u001b[0m     \u001b[39m#return 1 / (1 + np.exp(np.clip(-x, a_min=-100, a_max=100)))\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mvectorize(\u001b[39mlambda\u001b[39;49;00m x: x \u001b[39mif\u001b[39;49;00m x \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m0\u001b[39;49m)(x)\n",
      "File \u001b[0;32m~/Documents/NeuralNetworks/venv/lib/python3.9/site-packages/numpy/lib/function_base.py:2372\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_stage_2(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   2370\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m-> 2372\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_as_normal(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/NeuralNetworks/venv/lib/python3.9/site-packages/numpy/lib/function_base.py:2365\u001b[0m, in \u001b[0;36mvectorize._call_as_normal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     vargs \u001b[39m=\u001b[39m [args[_i] \u001b[39mfor\u001b[39;00m _i \u001b[39min\u001b[39;00m inds]\n\u001b[1;32m   2363\u001b[0m     vargs\u001b[39m.\u001b[39mextend([kwargs[_n] \u001b[39mfor\u001b[39;00m _n \u001b[39min\u001b[39;00m names])\n\u001b[0;32m-> 2365\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize_call(func\u001b[39m=\u001b[39;49mfunc, args\u001b[39m=\u001b[39;49mvargs)\n",
      "File \u001b[0;32m~/Documents/NeuralNetworks/venv/lib/python3.9/site-packages/numpy/lib/function_base.py:2455\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2452\u001b[0m \u001b[39m# Convert args to object arrays first\u001b[39;00m\n\u001b[1;32m   2453\u001b[0m inputs \u001b[39m=\u001b[39m [asanyarray(a, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args]\n\u001b[0;32m-> 2455\u001b[0m outputs \u001b[39m=\u001b[39m ufunc(\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2457\u001b[0m \u001b[39mif\u001b[39;00m ufunc\u001b[39m.\u001b[39mnout \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2458\u001b[0m     res \u001b[39m=\u001b[39m asanyarray(outputs, dtype\u001b[39m=\u001b[39motypes[\u001b[39m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m, in \u001b[0;36mPerceptron.relu.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrelu\u001b[39m(x):\n\u001b[1;32m     18\u001b[0m     \u001b[39m#return 1 / (1 + np.exp(np.clip(-x, a_min=-100, a_max=100)))\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mvectorize(\u001b[39mlambda\u001b[39;00m x: x \u001b[39mif\u001b[39;00m x \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "perceptron = Perceptron(layers=(784, 32, 32, 32, 10), optimizer=SGD(0.01))\n",
    "perceptron.train(\n",
    "    training_data=training_data,\n",
    "    test_data=test_data,\n",
    "    epochs=epochs,\n",
    "    batch_size=70,\n",
    "    loss_func=CategorialCrossEntropy(),\n",
    "    is_loss_funcs_plot_needed=True\n",
    ")\n",
    "score, _ = perceptron.predict(test_data=test_data)\n",
    "print(f'Accuracy of guessed numbers: {score: .2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование методов оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization method: SGD\n",
      "Accuracy of guessed numbers: 92.07%\n",
      "Optimization method: NAG\n",
      "Accuracy of guessed numbers: 95.09%\n",
      "Optimization method: Adagrad\n",
      "Accuracy of guessed numbers: 93.63%\n",
      "Optimization method: Adam\n",
      "Accuracy of guessed numbers: 95.26%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApcAAAGdCAYAAABHH1hqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABjbUlEQVR4nO3dd3gUdf4H8Pds380mm4SQSoCAkdA7AbGgUk6ROzw9sVBE9O7HoYLcWVAR9BQsh2IBOTSc2OE8xV6QO8RCRzyVEFogoaSQtiXZPr8/tiSbRhI2md3s+/U8++zszOzuJwSdN982giiKIoiIiIiIgkAmdQFERERE1HkwXBIRERFR0DBcEhEREVHQMFwSERERUdAwXBIRERFR0DBcEhEREVHQMFwSERERUdAwXBIRERFR0CikLqAl3G43Tp8+jejoaAiCIHU5RERE1AKiKMJkMiE1NRUyGduzIkVYhMvTp08jPT1d6jKIiIioDQoLC9GtWzepy6AOEhbhMjo6GoDnL2dMTIzE1RAREVFLGI1GpKen+6/jFBnCIlz6usJjYmIYLomIiMIMh7RFFg6AICIiIqKgYbgkIiIioqBhuCQiIiKioAmLMZdERETUOblcLjgcDqnLoHOQy+VQKBQtGj/LcElERESSMJvNOHnyJERRlLoUagGdToeUlBSoVKpmz2t1uNy2bRueeeYZ7N27F2fOnMEHH3yAqVOnNnn++++/j5dffhn79++HzWZD//79sXTpUkyaNKm1X01ERESdhMvlwsmTJ6HT6dC1a1fOKA9hoijCbrejtLQU+fn5yMzMbHZR/FaHS4vFgsGDB+O2227D73//+3Oev23bNkyYMAHLli1DbGws/vnPf2LKlCnYuXMnhg4d2tqvJyIiok7A4XBAFEV07doVWq1W6nLoHLRaLZRKJU6cOAG73Q6NRtPkua0Ol1dddRWuuuqqFp+/cuXKgNfLli3Dhx9+iI8//pjhkoiIKMKxxTJ8tPQWnh0+5tLtdsNkMiE+Pr7Jc2w2G2w2m/+10WjsiNKIiIiI6Dx1+FJEf//732E2m3HDDTc0ec7y5cthMBj8D95XnIiIiCg8dGi4fPvtt/Hoo49i48aNSExMbPK8RYsWoaqqyv8oLCzswCqJiIiIqK06LFy+++67uP3227Fx40aMHz++2XPVarX/PuK8nzgRERGFktLSUsydOxfdu3eHWq1GcnIyJk2ahO+//95/zo8//ohp06YhJSUFarUaPXr0wDXXXIOPP/7Yv/TS8ePHIQiC/xEdHY3+/ftj3rx5OHz4sFQ/3nnrkHD5zjvvYPbs2XjnnXcwefLkjvjKFnl7ZwHufHsfSoxWqUshIiKiMHHdddfhxx9/xPr163Ho0CF89NFHGDduHMrKygAAH374IUaPHg2z2Yz169cjNzcXX3zxBa699lo8/PDDqKqqCvi8r7/+GmfOnMFPP/2EZcuWITc3F4MHD8aWLVuk+PHOW6sn9JjNZhw5csT/Oj8/H/v370d8fDy6d++ORYsW4dSpU3j99dcBeLrCZ82aheeffx7Z2dkoKioC4JnSbjAYgvRjtM1bO0/g19NGTOyfjN8OTpW0FiIiokgmiiJqHC5JvlurlLd41nplZSW+/fZbbN26FZdddhkAoEePHhg1ahQAz5KNc+bMweTJk/H+++8HvLdv376YM2dOg0Xju3TpguTkZABAr169MGXKFFx55ZWYM2cOjh49Crlcfr4/Yodqdbjcs2cPLr/8cv/rhQsXAgBmzZqF1157DWfOnEFBQYH/+Nq1a+F0OjFv3jzMmzfPv993vpSyM7rg19NG7DxWxnBJREQkoRqHC/0e+VKS7z7w2CToVC2LRHq9Hnq9Hps2bcLo0aOhVqsDjn/11VcoKyvDfffd1+RnnCvIymQyzJ8/H9deey327t3rD67hotXd4uPGjYMoig0evqD42muvYevWrf7zt27d2uz5UhqV4VkOaVd+ucSVEBERUThQKBR47bXXsH79esTGxmLs2LF48MEH8b///Q8AcOjQIQBAnz59/O/ZvXu3P5Tq9Xp88skn5/yerKwsAJ5xmeEmou8t7guXh0vMKDPb0EWvPsc7iIiIqD1olXIceEyaW0Nrla3rdr7uuuswefJkfPvtt9ixYwc+//xzPP3003j11VcbPX/QoEHYv38/ACAzMxNOp/Oc3+HrOg/HReYjOlzGR6nQJykaecUm7D5ejt8MSJG6JCIioogkCEKLu6ZDgUajwYQJEzBhwgQsXrwYt99+O5YsWYLnnnsOAJCXl4fRo0cD8KyCc8EFF7Tq83NzcwEAGRkZwS28A3T4Iuqhxtd6ueMYu8aJiIiobfr16weLxYKJEyciPj4eTz31VJs/y+1244UXXkBGRkZY3io7fP6J0E6ye8XjjR0nOO6SiIiIzqmsrAx/+MMfcNttt2HQoEGIjo7Gnj178PTTT+N3v/sd9Ho9Xn31VUybNg2TJ0/G3XffjczMTJjNZnzxxRcA0GD2d1lZGYqKilBdXY1ffvkFK1euxK5du/Dpp5+G3UxxgOHS33KZW2REVbUDBp1S4oqIiIgoVOn1emRnZ+O5557D0aNH4XA4kJ6ejjvuuAMPPvggAODaa6/FDz/8gKeeegozZ85EeXk5DAYDRowYgXfffRfXXHNNwGf6bi6j0+nQo0cPXH755Vi7dm2ru9JDhSDWX2wpBBmNRhgMBlRVVbXL3Xqu+PtWHDtrQc6sEbiyb1LQP5+IiCgSNXf9tlqtyM/PR0ZGBjQajUQVUmu09HcW8WMugdrWy53sGiciIiI6LwyX8Iy7BICdx8okroSIiIgovDFcAhiV0QUA8MtpI8y2c689RURERESNY7gEkBarRbc4LVxuEXtPVEhdDhEREVHYYrj0yva2Xu7KZ9c4ERERUVsxXHpl+yb1cDF1IiIiojZjuPTyTer56WQlrA6XxNUQERERhSeGS6/u8TokxajhcInYV8Bxl0RERERtwXDpJQhCnXGX7BonIiIiaguGyzpGcdwlERERNePWW2+FIAh48sknA/Zv2rQJgiA0OD8rKwtqtRpFRUWNft5///tfXHPNNejatSs0Gg169+6NadOmYdu2be1Sf0dguKxjtHfc5b6CCticHHdJREREDWk0Gjz11FOoqGh+GN13332HmpoaXH/99Vi/fn2D46tXr8aVV16JLl26YMOGDcjLy8MHH3yAiy66CPfcc097ld/uGC7r6N1Vjy5RKticbvx8skrqcoiIiCgEjR8/HsnJyVi+fHmz5+Xk5ODmm2/GjBkzsG7duoBjBQUFWLBgARYsWID169fjiiuuQI8ePTBo0CDMnz8fe/bsac8foV0xXNYhCALvM05ERCQFUQTsFmkeotiqUuVyOZYtW4YXX3wRJ0+ebPQck8mEf/3rX5g+fTomTJiAqqoqfPvtt/7j//73v+FwOHDfffc1+v7GutjDhULqAkJNdkY8Pv+lCDvzyzHvcqmrISIiihCOamBZqjTf/eBpQBXVqrdce+21GDJkCJYsWYKcnJwGx999911kZmaif//+AIAbb7wROTk5uOSSSwAAhw4dQkxMDJKTk/3v+fe//41Zs2b5X2/fvh0DBw5sy08kKbZc1uO7z/je4+VwutwSV0NERESh6qmnnsL69euRm5vb4Ni6deswffp0/+vp06fjX//6F0wmk39f/dbJSZMmYf/+/fj0009hsVjgcoXn/A+2XNaTlRyNGI0CRqsTv542YnB6rNQlERERdX5KnacFUarvboNLL70UkyZNwqJFi3Drrbf69x84cAA7duzArl27cP/99/v3u1wuvPvuu7jjjjuQmZmJqqoqFBUV+Vsv9Xo9LrjgAigU4R3P2HJZj0xWd9wl7zNORETUIQTB0zUtxeM8xjc++eST+Pjjj7F9+3b/vpycHFx66aX46aefsH//fv9j4cKF/i7066+/HkqlEk899dR5/9GFmvCOxu0kO6MLvs4twc5j5fjjpb2lLoeIiIhC1MCBA3HLLbfghRdeAAA4HA688cYbeOyxxzBgwICAc2+//XY8++yz+PXXX9G/f3+sWLEC8+fPR3l5OW699VZkZGSgvLwcb775JgDPxKFwxJbLRvhaLncdL4fL3boZZERERBRZHnvsMbjdnnkaH330EcrKynDttdc2OK9v377o27evv/XyrrvuwldffYXS0lJcf/31yMzMxNVXX438/Hx88cUXYTmZB2DLZaP6p8YgSiWHyerEwSIj+qcapC6JiIiIQsBrr73WYF/Pnj1hs9n8r5ubiHPgwIGA1+PHj8f48eODVl8oYMtlIxRyGYb39LZecr1LIiIiohZjuGxCNu8zTkRERNRqDJdN8N1nfNfxcoitXLmfiIiIKFIxXDZhYFosNEoZyi12HCkxS10OERERUVhguGyCSiHDsO5xAHifcSIiIqKWYrhsRu1i6gyXRERERC3BcNmMbO99xnceK+O4SyIiIqIWYLhsxtDusVDJZSgx2XCirFrqcoiIiIhCHsNlMzRKOQanexZQ533GiYiIiM6N4fIc/F3jHHdJREREbbB06VIMGTJE6jKaNW7cOCxYsCAon8VweQ6juJg6ERER1bN9+3bI5XJMnjxZ6lJCDsPlOQzvEQe5TMCpyhqcrOC4SyIiIgJycnJw1113Ydu2bTh9+rTU5QAAHA6H1CUAYLg8pyi1AgPSPOMueZ9xIiIiMpvN2LBhA+bOnYvJkyfjtddeCzj+5JNPIikpCdHR0ZgzZw6sVmvA8d27d2PChAlISEiAwWDAZZddhn379gWcc/DgQVx88cXQaDTo168fvv76awiCgE2bNgEAjh8/DkEQsGHDBlx22WXQaDR46623UFZWhptuuglpaWnQ6XQYOHAg3nnnnYDPtlgsmDlzJvR6PVJSUrBixYqg/vkwXLbAaHaNExERtStRFFHtqJbk0drlBjdu3IisrCz06dMH06dPx7p16/yfsXHjRixduhTLli3Dnj17kJKSgtWrVwe832QyYdasWfjuu++wY8cOZGZm4uqrr4bJZAIAuFwuTJ06FTqdDjt37sTatWvx0EMPNVrLAw88gPnz5yM3NxeTJk2C1WrF8OHD8emnn+KXX37BH//4R8yYMQO7du3yv+fee+/FN998gw8//BBfffUVtm7d2iDcng9F0D6pExuVEY9/bDuGXccZLomIiNpDjbMG2W9nS/LdO2/eCZ1S1+Lzc3JyMH36dADAb37zG1RVVeGbb77BuHHjsHLlSsyZMwdz5swBADz++OP4+uuvA1ovr7jiioDPW7t2LWJjY/HNN9/gmmuuwebNm3H06FFs3boVycnJAIAnnngCEyZMaFDLggUL8Pvf/z5g31//+lf/9l133YUvv/wSGzduxKhRo2A2m5GTk4M333wTV155JQBg/fr16NatW4t//nNhy2ULjOgZD0EA8s9aUGK0nvsNRERE1Cnl5eVh165duOmmmwAACoUC06ZNQ05ODgAgNzcX2dmBIXnMmDEBr4uLi3HHHXcgMzMTBoMBMTExMJvNKCgo8H9Henq6P1gCwKhRoxqtZ8SIEQGvXS4X/va3v2HgwIGIj4+HXq/Hl19+6f/so0ePwm63B9QYHx+PPn36tOWPo1FsuWwBg1aJvskxOHDGiJ355ZgyOFXqkoiIiDoVrUKLnTfvlOy7WyonJwdOpxOpqbVZQBRFqNVqvPTSSy36jFmzZqGsrAzPP/88evToAbVajTFjxsBut7e69qioqIDXzzzzDJ5//nmsXLkSAwcORFRUFBYsWNCmz24rhssWyu4V7w2XZQyXREREQSYIQqu6pqXgdDrx+uuvY8WKFZg4cWLAsalTp+Kdd95B3759sXPnTsycOdN/bMeOHQHnfv/991i9ejWuvvpqAEBhYSHOnj3rP96nTx8UFhaiuLgYSUlJADyTgFri+++/x+9+9zt/t73b7cahQ4fQr18/AEDv3r2hVCqxc+dOdO/eHQBQUVGBQ4cO4bLLLmvNH0eTGC5bKDujC/75/XHOGCciIopQn3zyCSoqKjBnzhwYDIaAY9dddx1ycnLw17/+FbfeeitGjBiBsWPH4q233sKvv/6KXr16+c/NzMzEG2+8gREjRsBoNOLee++FVlvbejphwgT07t0bs2bNwtNPPw2TyYSHH34YgCeENyczMxPvvfcefvjhB8TFxeHZZ59FcXGxP1zq9XrMmTMH9957L7p06YLExEQ89NBDkMmCN1KSYy5byLeY+qFiM8otHde0TERERKEhJycH48ePbxAsAU+43LNnD/r27YvFixfjvvvuw/Dhw3HixAnMnTu3wedUVFRg2LBhmDFjBu6++24kJib6j8vlcmzatAlmsxkjR47E7bff7p8trtFomq3x4YcfxrBhwzBp0iSMGzcOycnJmDp1asA5zzzzDC655BJMmTIF48ePx8UXX4zhw4e38U+lIUFs7fx7CRiNRhgMBlRVVSEmJkayOiY+9w0OFZuxZvpw/GZA8rnfQEREFMGau35brVbk5+cjIyPjnIGJPN3dF198MY4cOYLevXtLUkNLf2fsFm+FURnxOFRsxs78MoZLIiIiajcffPAB9Ho9MjMzceTIEcyfPx9jx46VLFi2BrvFWyE7owsALqZORERE7ctkMmHevHnIysrCrbfeipEjR+LDDz+UuqwWYctlK2R7x13mFhlRVeOAQauUuCIiIiLqjGbOnBkw4zycsOWyFRJjNMhIiIIoAnt4tx4iIiKiBhguW2lUT0/rJZckIiIiImqI4bKVsnt5wuUOhksiIiKiBlodLrdt24YpU6YgNTUVgiBg06ZN53zP1q1bMWzYMKjValxwwQV47bXX2lBqaMju5ZnU88upKlhsTomrISIiIgotrQ6XFosFgwcPxqpVq1p0fn5+PiZPnozLL78c+/fvx4IFC3D77bfjyy+/bHWxoSAtVou0WC1cbhF7T1RIXQ4RERFRSGn1bPGrrroKV111VYvPX7NmDTIyMrBixQoAQN++ffHdd9/hueeew6RJk1r79SEhu1c83t93Cjvzy3DphV2lLoeIiIgoZLT7mMvt27dj/PjxAfsmTZqE7du3N/kem80Go9EY8AglviWJOKmHiIiIzmXp0qUYMmSI1GV0mHYPl0VFRUhKSgrYl5SUBKPRiJqamkbfs3z5chgMBv8jPT29vctsFd9i6j8VVsHqcElcDREREXW07du3Qy6XY/LkyVKXEnJCcrb4okWLUFVV5X8UFhZKXVKAHl10SIxWw+5y48eCSqnLISIiog6Wk5ODu+66C9u2bcPp06elLiektHu4TE5ORnFxccC+4uJixMTEQKvVNvoetVqNmJiYgEcoEQTBP2t8Z36ZxNUQERFRRzKbzdiwYQPmzp2LyZMnN1gF58knn0RSUhKio6MxZ84cWK3WgOO7d+/GhAkTkJCQAIPBgMsuuwz79u0LOEcQBPzjH//ANddcA51Oh759+2L79u04cuQIxo0bh6ioKFx00UU4evRoe/+4rdbu4XLMmDHYsmVLwL7NmzdjzJgx7f3V7WoUx10SEREFjSiKcFdXS/IQRbFVtW7cuBFZWVno06cPpk+fjnXr1vk/Y+PGjVi6dCmWLVuGPXv2ICUlBatXrw54v8lkwqxZs/Ddd99hx44dyMzMxNVXXw2TyRRw3t/+9jfMnDkT+/fvR1ZWFm6++Wb86U9/wqJFi7Bnzx6Ioog777zz/P7g20GrZ4ubzWYcOXLE/zo/Px/79+9HfHw8unfvjkWLFuHUqVN4/fXXAQD/93//h5deegn33XcfbrvtNvznP//Bxo0b8emnnwbvp5DAaG+43FdQAbvTDZUiJEcYEBERhQWxpgZ5w4ZL8t199u2FoNO1+PycnBxMnz4dAPCb3/wGVVVV+OabbzBu3DisXLkSc+bMwZw5cwAAjz/+OL7++uuA1ssrrrgi4PPWrl2L2NhYfPPNN7jmmmv8+2fPno0bbrgBAHD//fdjzJgxWLx4sX+1nfnz52P27Nlt+6HbUasT0Z49ezB06FAMHToUALBw4UIMHToUjzzyCADgzJkzKCgo8J+fkZGBTz/9FJs3b8bgwYOxYsUKvPrqq2G7DJHPBYl6xEepYHW48fOpSqnLISIiog6Ql5eHXbt24aabbgIAKBQKTJs2DTk5OQCA3NxcZGdnB7ynfm9tcXEx7rjjDmRmZsJgMCAmJgZmszkgPwHAoEGD/Nu+ydEDBw4M2Ge1WkNuVZ1Wt1yOGzeu2ebjxu6+M27cOPz444+t/aqQJggCRvWMxxe/FmHHsXIM7xEvdUlERERhS9Bq0WffXsm+u6VycnLgdDqRmprq3yeKItRqNV566aUWfcasWbNQVlaG559/Hj169IBarcaYMWNgt9sDzlMqlbU1CkKT+9xud4vr7witDpdUK7uXJ1zuzC/HvMulroaIiCh8CYLQqq5pKTidTrz++utYsWIFJk6cGHBs6tSpeOedd9C3b1/s3LkTM2fO9B/bsWNHwLnff/89Vq9ejauvvhoAUFhYiLNnz7b/D9BBGC7Pg29Sz97j5XC63FDIOe6SiIios/rkk09QUVGBOXPmwGAwBBy77rrrkJOTg7/+9a+49dZbMWLECIwdOxZvvfUWfv31V/Tq1ct/bmZmJt544w2MGDECRqMR9957b5Mr6IQjpqHzkJUcgxiNAha7C7+eDq3xDkRERBRcOTk5GD9+fINgCXjC5Z49e9C3b18sXrwY9913H4YPH44TJ05g7ty5DT6noqICw4YNw4wZM3D33XcjMTGxo36MdieIrZ1/LwGj0QiDwYCqqqqQW/Nyzmu7seVgCR66ui/uuLTXud9AREQUIZq7flutVuTn5yMjIwMajUaiCqk1Wvo7Y8vlecru5eka52LqRERERAyX522U9z7ju/LL4XaHfCMwERERUbtiuDxPA1JjEKWSw2h14mCR6dxvICIiIurEGC7Pk0Iuw/Ce7BonIiIiAhgugyKb9xknIiIiAsBwGRR1w2UYTL4nIiIKGbxuho+W/q4YLoNgYDcD1AoZyix2HC01S10OERFRyJPL5QDQ4JaHFLqqq6sBBN6CsjG8Q08QqBVyDOseh+3HyrDjWDkuSIyWuiQiIqKQplAooNPpUFpaCqVSCZmM7V2hShRFVFdXo6SkBLGxsf5/GDSF4TJIRmXEY/uxMuzKL8f00T2kLoeIiCikCYKAlJQU5Ofn48SJE1KXQy0QGxuL5OTkc57HcBkk2b3igS2eGeOiKEIQBKlLIiIiCmkqlQqZmZnsGg8DSqXynC2WPgyXQTI0PQ5KuYBiow0F5dXo0SVK6pKIiIhCnkwm4+0fOxkOcAgSrUqOwd1iAQA7j3FJIiIiIopMDJdB5LvP+A4upk5EREQRiuEyiOreZ5yIiIgoEjFcBtHwHnGQywScrKjBqcoaqcshIiIi6nAMl0GkVyswIDUGALCLXeNEREQUgRgugyy7l6drnJN6iIiIKBIxXAbZqJ619xknIiIiijQMl0E2smc8BAE4dtaCEqNV6nKIiIiIOhTDZZAZdEpkJXvGXe5k6yURERFFGIbLdpCdwa5xIiIiikwMl+1gtHcx9Z2cMU5EREQRhuGyHYz0Tuo5VGxGucUucTVEREREHYfhsh100auRmagHwK5xIiIiiiwMl+1kFMddEhERUQRiuGwn/sXUOe6SiIiIIgjDZTvxzRg/cMYIo9UhcTVEREREHYPhsp0kxWjQs4sOogjsOc6ucSIiIooMDJftKDuD9xknIiKiyMJw2Y58k3p4px4iIiKKFAyX7Sjbu5j6z6eqYLE5Ja6GiIiIqP0xXLajbnE6pMVq4XKL2FdQIXU5RERERO2O4bKd+WaNc9wlERERRQKGy3bGxdSJiIgokjBctjPfYur7CythdbgkroaIiIiofTFctrOeXXToGq2G3eXG/sJKqcshIiIialcMl+1MEASOuyQiIqKIwXDZAXifcSIiIooUDJcdwNdyua+gAnanW+JqiIiIiNoPw2UHyEzUIz5KBavDjZ9PVUpdDhEREVG7YbjsAIIgYGTPOAC8FSQRERF1bgyXHSQ7wzvukpN6iIiIqBNjuOwgvsXU956ogNPFcZdERETUOTFcdpC+KTGI1ihgtjlx4IxR6nKIiIiI2gXDZQeRywSM7Mn1LomIiKhzY7jsQP7F1Dmph4iIiDophssO5FtMfffxcrjdosTVEBEREQUfw2UH6p8aA51KjqoaB/KKTVKXQ0RERBR0DJcdSCmXYXgP73qXx3grSCIiIup82hQuV61ahZ49e0Kj0SA7Oxu7du1q9vyVK1eiT58+0Gq1SE9Pxz333AOr1dqmgsOdb9zlruMcd0lERESdT6vD5YYNG7Bw4UIsWbIE+/btw+DBgzFp0iSUlJQ0ev7bb7+NBx54AEuWLEFubi5ycnKwYcMGPPjgg+ddfDjyjbvclV8OUeS4SyIiIupcWh0un332Wdxxxx2YPXs2+vXrhzVr1kCn02HdunWNnv/DDz9g7NixuPnmm9GzZ09MnDgRN9100zlbOzurQd0MUCtkOGu242ipRepyiIiIiIKqVeHSbrdj7969GD9+fO0HyGQYP348tm/f3uh7LrroIuzdu9cfJo8dO4bPPvsMV199dZPfY7PZYDQaAx6dhVohx9DusQCAnfkcd0lERESdS6vC5dmzZ+FyuZCUlBSwPykpCUVFRY2+5+abb8Zjjz2Giy++GEqlEr1798a4ceOa7RZfvnw5DAaD/5Gent6aMkPeKN5nnIiIiDqpdp8tvnXrVixbtgyrV6/Gvn378P777+PTTz/F3/72tybfs2jRIlRVVfkfhYWF7V1mhxrtm9TDcZdERETUyShac3JCQgLkcjmKi4sD9hcXFyM5ObnR9yxevBgzZszA7bffDgAYOHAgLBYL/vjHP+Khhx6CTNYw36rVaqjV6taUFlaGdo+DUi6gyGhFQXk1enSJkrokIiIioqBoVculSqXC8OHDsWXLFv8+t9uNLVu2YMyYMY2+p7q6ukGAlMvlABCxrXZalRyDusUC4K0giYiIqHNpdbf4woUL8corr2D9+vXIzc3F3LlzYbFYMHv2bADAzJkzsWjRIv/5U6ZMwcsvv4x3330X+fn52Lx5MxYvXowpU6b4Q2Yk8t9nnOMuiYiIqBNpVbc4AEybNg2lpaV45JFHUFRUhCFDhuCLL77wT/IpKCgIaKl8+OGHIQgCHn74YZw6dQpdu3bFlClT8MQTTwTvpwhDozLisXrrUew6zhnjRERE1HkIYhj0TRuNRhgMBlRVVSEmJkbqcoLCbHNi0NIv4RaBHx64AqmxWqlLIiIiCqrOeP2mc+O9xSWiVyswIM0AgOtdEhERUefBcCmh7DpLEhERERF1BgyXEuJi6kRERNTZMFxKaFTPeAgCcOysBSUmq9TlEBEREZ03hksJGXRKZCV7Bjiza5yIiIg6A4ZLiXHcJREREXUmDJcS42LqRERE1JkwXEpspDdc5hWbUGGxS1wNERER0flhuJRYgl6NCxL1AIBdx9l6SUREROGN4TIEjGLXOBEREXUSDJchwD+ph/cZJyIiojDHcBkCsr2LqR84bYTR6pC4GiIiIqK2Y7gMAckGDXp00cEtAnuPV0hdDhEREVGbMVyGCF/X+I58do0TERFR+GK4DBG++4xzMXUiIiIKZwyXIcLXcvnzySpU250SV0NERETUNgyXIaJbnBapBg2cbhF7T3DcJREREYUnhssQIQgCsnuxa5yIiIjCG8NlCOFi6kRERBTuGC5DiG/c5f7CSlgdLomrISIiImo9hssQkpEQhQS9GnaXG/sLK6Uuh4iIiKjVGC5DiGfcpfdWkBx3SURERGGI4TLEjPaNu+Ri6kRERBSGGC5DjG8x9b0nKmB3uiWuhoiIiKh1GC5DTGaiHnE6JawON34+VSV1OUREREStwnAZYmQyASN7smuciIiIwhPDZQjiYupEREQUrhguQ5Bvvcs9xyvgdHHcJREREYUPhssQ1DclBtEaBcw2J3LPmKQuh4iIiKjFGC5DkJzjLomIiChMMVyGKP99xjnukoiIiMIIw2WI8o273H28HG63KHE1RERERC3DcBmiBqQZoFPJUVntQF4xx10SERFReGC4DFFKuQzDe8QB4JJEREREFD4YLkPYKE7qISIiojDDcBnC6i6mLoocd0lEREShj+EyhA3qZoBKIcNZsx1HSy1Sl0NERER0TgyXIUyjlGNoeiwAjrskIiKi8MBwGeJ8XeMcd0lEREThgOEyxPnWu9x5jOMuiYiIKPQxXIa4Yd3joJAJKDJaUVheI3U5RERERM1iuAxxWpUcg7oZAAA72DVOREREIY7hMgzUXZKIiIiIKJQxXIaBURlcTJ2IiIjCA8NlGBjRIw4yASgsr8HpSo67JCIiotDFcBkGojVK9E/1jLtk1zgRERGFMobLMOFfkojhkoiIiEIYw2WY4GLqREREFA4YLsPEyJ5xEATgWKkFJSar1OUQERERNYrhMkzE6lTokxQNANidXyFxNURERESNY7gMI9lckoiIiIhCHMNlGOFi6kRERBTqGC7DyMienpbLg0UmVFjsEldDRERE1FCbwuWqVavQs2dPaDQaZGdnY9euXc2eX1lZiXnz5iElJQVqtRoXXnghPvvsszYVHMm6RqvRu2sUAGD3cbZeEhERUehpdbjcsGEDFi5ciCVLlmDfvn0YPHgwJk2ahJKSkkbPt9vtmDBhAo4fP4733nsPeXl5eOWVV5CWlnbexUeiURm+JYkYLomIiCj0tDpcPvvss7jjjjswe/Zs9OvXD2vWrIFOp8O6desaPX/dunUoLy/Hpk2bMHbsWPTs2ROXXXYZBg8efN7FR6LRvTxd4xx3SURERKGoVeHSbrdj7969GD9+fO0HyGQYP348tm/f3uh7PvroI4wZMwbz5s1DUlISBgwYgGXLlsHlcjX5PTabDUajMeBBHqO8M8Z/PV0Fo9UhcTVEREREgVoVLs+ePQuXy4WkpKSA/UlJSSgqKmr0PceOHcN7770Hl8uFzz77DIsXL8aKFSvw+OOPN/k9y5cvh8Fg8D/S09NbU2anlmLQonu8Dm4R2Huc610SERFRaGn32eJutxuJiYlYu3Ythg8fjmnTpuGhhx7CmjVrmnzPokWLUFVV5X8UFha2d5lhhfcZJyIiolClaM3JCQkJkMvlKC4uDthfXFyM5OTkRt+TkpICpVIJuVzu39e3b18UFRXBbrdDpVI1eI9arYZarW5NaRFlVEY8/rX3JBdTJyIiopDTqpZLlUqF4cOHY8uWLf59brcbW7ZswZgxYxp9z9ixY3HkyBG43W7/vkOHDiElJaXRYEnnNtq7mPrPJ6tQbXdKXA0RERFRrVZ3iy9cuBCvvPIK1q9fj9zcXMydOxcWiwWzZ88GAMycOROLFi3ynz937lyUl5dj/vz5OHToED799FMsW7YM8+bNC95PEWG6xWmRYtDA6Rax70Sl1OUQERER+bWqWxwApk2bhtLSUjzyyCMoKirCkCFD8MUXX/gn+RQUFEAmq82s6enp+PLLL3HPPfdg0KBBSEtLw/z583H//fcH76eIMIIgIDsjHpv2n8au/DJcnJkgdUlEREREAABBFEVR6iLOxWg0wmAwoKqqCjExMVKXExLe3lmABz/4GaMy4rHxT40PSSAiIpISr9+RifcWD1PZ3sXU9xdWwupoes1QIiIioo7EcBmmeiVEIUGvht3pxk+FlVKXQ0RERASA4TJs+cZdAlzvkoiIiEIHw2UYy+Z9xomIiCjEMFyGMd99xveeqIDD5T7H2URERETtj+EyjF2YGI1YnRI1Dhd+PlUldTlEREREDJfhTCYTMLKnd9zlMXaNExERkfQYLsOcb1LPLt5nnIiIiEIAw2WYy87w3Gd8z/EKuNwhvx4+ERERdXIMl2GuX2oMotUKmGxOjrskIiIiyTFchjm5TPAvSXT7+j3478ESiSsiIiKiSMZw2Qk8NLkfMhP1OGu2YfZru/HQBz+j2u6UuiwiIiKKQAyXnUBGQhQ+vuti3DY2AwDw1s4CTH7hO/xYUCFxZURERBRpGC47CY1Sjkem9MNbt2cjOUaD/LMWXL9mO57bfIgLrBMREVGHYbjsZMZekIAvF1yK3w5Ohcst4vkth3H9yz/gWKlZ6tKIiIgoAjBcdkIGnRIv3DQUz984BDEaBX46WYWrX/gWb+w4AVHkckVERETUfhguO7HfDUnDFwsuxdgLusDqcGPxpl8w+7XdKDFapS6NiIiIOimGS7tF6graVWqsFm/clo1HrukHlUKGrXmlmLRyG7745YzUpREREVEnFLnh0uUEvnkaeGEoYCqWupp2JZMJuO3iDHxy18XolxKDimoH/u/NffjLxp9gsjqkLo+IiIg6kcgNl6IbyP0IMBcDn9wDRMBYxAuTorFp3ljMHdcbggD8e99J/Gblt9iVXy51aURERNRJRG64VKiAqS8DMiWQ9ynwv41SV9QhVAoZ7v9NFjb+aQy6xWlxqrIG09Zux5OfH4TN6ZK6PCIiIgpzkRsuASB5IHDZ/Z7tz+8FjJEzDnFkz3h8Pv8S3DCiG0QRWPPNUUxd9QPyikxSl0ZERERhLLLDJQBcfA+QMgSwVgEfz4+I7nGfaI0ST18/GGumD0d8lAq5Z4yY8tJ3ePXbY3C7I+fPgYiIiIKH4VKuAK5dA8hVwOEvgf1vS11Rh/vNgGR8seASXJGVCLvTjcc/zcUtr+7E6coaqUsjIiKiMMNwCQCJfYHLH/Rsf/EAUHVK2nokkBitQc6sEXji2gHQKuXYfqwMk1Zuw4f7T3HhdSIiImqxiA6XP5X+hPu23QeH2wGMuQtIGwHYjMBHd0VU97iPIAi4JbsHPpt/CYakx8JkdWL+u/tx1zs/orLaLnV5REREFAYiNlxWO6px15a78Hn+53hs+2MQZXLP7HG5Gji6Bdj3utQlSiYjIQrv/d8Y3DP+QshlAj753xn8ZuW3+PZwqdSlERERUYiL2HCpU+rw+MWPQybIsOnIJqz5aQ3Q9ULgysWeE758CKgskLZICSnkMswfn4l/z70IGQlRKDJaMSNnF5Z+9CusDi5ZRERERI2L2HAJAJd2uxQPZT8EAFj902psOrIJGP1nID0bsJuAD+8E3G5pi5TYkPRYfHr3xZgxugcA4LUfjuOaF7/DL6eqJK6MiIiIQlFEh0sAuKHPDZgzYA4A4NEfHsUPRTuB360GFFog/xtg7zqJK5SeTqXA36YOwD9nj0TXaDWOlJgxddX3WPXfI3BxySIiIiKqI+LDJQDcPexuXJ1xNZyiEwu3LkSezAWMX+I5+NUjQHm+tAWGiMv7JOLLBZfiN/2T4XSLeObLPNzwj+0oKKuWujQiIiIKEQyXAGSCDH8b+zeMSBoBi8OCP2/5M4r6TwV6jAUcFnaP1xEfpcLL04fh738YDL1agb0nKnDV89uwYXcBlywiIiIihksflVyFlZevRG9Db5RUl+DP/50H09VPA8oo4MR3wO5XpC4xZAiCgOuHd8Pn8y/BqJ7xsNhduP/fP+OPb+zFWbNN6vKIiIhIQgyXdRjUBqwevxoJ2gQcrjiMhT89D8f4RzwHNy8Byo5KW2CISY/X4Z0/jsYDV2VBKRew+UAxfrNyG74+UCx1aURERCQRhst6UvWpWHXlKmgVWuw4swNL7QUQMy4BnDXApj8Dbi7DU5dcJuD/LuuND+ddjAuT9DhrtuP21/dg0fv/g8XmlLo8IiIi6mAMl43o16UfVly2AnJBjo+OfYzVF14EqPRA4Q5g5xqpywtJ/VJj8NGdF+P2izMAAO/sKsTVL3yLvScqJK6MiIiIOhLDZRMu6XYJHh79MABgzaF38MHIGz0HtjwGnD0sYWWhS6OU4+Fr+uHt27ORatDgRFk1/rDmB6z4Kg8OFydEERERRQKGy2Zcf+H1uGPgHQCAR89swfcZ2YDTCmyay+7xZlx0QQI+X3Appg5JhVsEXvzPEfx+9Q84UmKWujQiIiJqZwyX53DX0LtwTa9r4BJdWKioxMGoOODkbmD7S1KXFtIMWiVW3jgUL940FAatEj+fqsLkF77F+h+Oc8kiIiKiTozh8hwEQcBjFz2GUcmjUO2swZ9Tk3FGLgf+8wRQclDq8kLelMGp+HLBpbgkMwE2pxtLPvoVs/65G8VGq9SlERERUTtguGwBpVyJ5y5/DhfEXoBSpwV/7p4Bo2gHNv0f4OKM6HNJNmiwfvYoLJ3SD2qFDNsOlWLSym347OczUpdGREREQcZw2UIxqhisvnI1ErWJOAI77klOgeP0j8D3K6UuLSzIZAJuHZuBT+66GAPSYlBZ7cCf39qHhRv2w2h1SF0eERERBQnDZSuk6FOwavwq6BQ67FIr8EjXLhC3PgkU/yp1aWEjMyka788dizsvvwAyAXj/x1O4auW32HGsTOrSiIiIKAgYLlspKz4Lz457FnJBjk/0UXjRoAM++D/Axda3llIpZPjrpD7Y+Kcx6B6vw6nKGtz0yg4s+ywXNidn4RMREYUzhss2GJs2FkvGLAEAvBJrwHuWo8C3z0pcVfgZ0TMen82/BDeOTIcoAmu3HcPvXvoe7+09iQqLXeryiIiIqA0EMQzWhTEajTAYDKiqqkJMTIzU5fit2r8Ka35aA7ko4sWSclwy4wsgZZDUZYWlr34twqL3f0aZN1TKBE/4nNgvCRP7JaN7F53EFRIRUWuF6vWb2hfD5XkQRREPf/cQPjr2MbRuN16zRaPf7dsAhUrq0sJSqcmGN7Yfx1cHinGwyBRwrE9SNCb0S8KEfkkYmGaATCZIVCUREbVUqF6/qX0xXJ4nh8uBP391B3aU7EWC04W30qcideIyqcsKe4Xl1dh8oBibDxRj1/FyuNy1f02TYtQY3zcJE/snY3SveKgVcgkrJSKipoTy9ZvaD8NlEJjsJszadC0O1xSjl92B1ye+CkOPi6Uuq9OorLbjPwdLsPlAMb45VIpqe+2kH71agcv6dMXEfkkY1ycRBq1SwkqJiKiuUL9+U/tguAySIksRbvn31SgRHRjhkuEft3wHlTpa6rI6HavDhe1Hy/DVgWJ8nVuMUpPNf0whE5DdKx4T+iZhQv9kpMVqJayUiIjC4fpNwcdwGUR5p3Zh1le3wSITcJU2HU/+4RPIBE7Iby9ut4ifTlZi84FifHWgGEdKzAHH+6fG+Mdp9kuJgSBwnCYRUUcKl+s3BRfDZZD9sONZzDu4Dk5BwO09JmP+uCelLili5J+1YPOBImw+UIw9JypQ9292WqwWE/olYWK/JIzMiIdSztBPRNTewun6TcHDcNkONr37Oyy2HQMALB75AG7od4vEFUWeMrMNW7zjNL89XAqrw+0/FqNR4IqsREzol4zL+nSFXq2QsFIios4r3K7fFBxtar5ZtWoVevbsCY1Gg+zsbOzatatF73v33XchCAKmTp3alq8NG1N/+0/82eIEADyx+0lsO7lN4ooiTxe9GjeMSMcrM0fgx8UTsXbGcPxheDfER6lgtDqxaf9pzHt7H4Y9thmz1u3CmztOoNholbpsIiKisNfqlssNGzZg5syZWLNmDbKzs7Fy5Ur861//Ql5eHhITE5t83/Hjx3HxxRejV69eiI+Px6ZNm1r8neH4Lx/x4Gd45Ot52BSth1amwj+veh39E/pLXVbEc7lF7Cuo8C9zlH/WEnB8cDcDJvZPxoR+SchM1HOcJhHReQjH6zedv1aHy+zsbIwcORIvvfQSAMDtdiM9PR133XUXHnjggUbf43K5cOmll+K2227Dt99+i8rKyk4fLgHA8f6fMK9kC7Zrteiiicdbk99Gmj5N6rLISxRFHC0148tfPUFzf2FlwPEeXXSemef9kjCiZzzkXLidiKhVwvX6TeenVeHSbrdDp9PhvffeC+janjVrFiorK/Hhhx82+r4lS5bgf//7Hz744APceuut5wyXNpsNNlvtEjNGoxHp6enh95ezphLml0fjVr2IPLUKGYYMvHHVGzCoDVJXRo0oMVrxdW4JNh8owvdHy2B31o7TjNMpcUVWEib2T8IlmQnQqThOk4joXBguI1OrrpBnz56Fy+VCUlJSwP6kpCQcPHiw0fd89913yMnJwf79+1v8PcuXL8ejjz7amtJCkzYW+ikvYtW703BLahLyq/Ix/7/zsXbCWqjkvEVkqEmM0eDm7O64Obs7LDYnth0qxeYDxdhysAQV1Q78e99J/HvfSagVMlySmYAJ/ZJwZd8kJOjVUpdOREQUMtq1+cVkMmHGjBl45ZVXkJCQ0OL3LVq0CAsXLvS/9rVchqXMCUgadDNW//IuZqWlYG/xXjz83cN48tInuQZmCItSK3DVwBRcNTAFTpcbu46X+8dpnqyowde5Jfg6twSC8DOGdY/DRO96mr266qUunYiISFLt2i2+f/9+DB06FHJ57b2f3W5PV6NMJkNeXh569+59zu8N+2Z1axWw+iLssJdibkoynBAxe8BsLBy+8NzvpZAiiiIOFpn8QfPnU1UBx3t3jcKEfp4JQQPTDFAp+A8IIopcYX/9pjZp04SeUaNG4cUXXwTgCYvdu3fHnXfe2WBCj9VqxZEjRwL2PfzwwzCZTHj++edx4YUXQqU6d/dwp/jLefQ/wBvX4iN9FB7q2gUA8FD2Q7gx60aJC6PzcaaqBl977xC041gZHK7a/5wUMgG9u+qRlRKNrOQY73M0kmM0nIVORBGhU1y/qdVa3S2+cOFCzJo1CyNGjMCoUaOwcuVKWCwWzJ49GwAwc+ZMpKWlYfny5dBoNBgwYEDA+2NjYwGgwf5Or/cVwIjb8Ns963Amqgte0gHLdy1HclQyxqWPk7o6aqMUgxYzxvTEjDE9YbQ6sDXPM05z26FSVNU4kFdsQl6xCR/itP89Bq0SWcnR6JsSgz7JnsDZJzmak4SIiKhTaPXVbNq0aSgtLcUjjzyCoqIiDBkyBF988YV/kk9BQQFkMnYFNmrCY8CRr/HH4gKczhqN922ncd+2+7Bu0joMSIiwsN0JxWiU+O3gVPx2cCpEUcTpKivyiozIPWPCwSITDp4x4thZC6pqHNiZX46d+eX+9woC0CNe5w2bMeibEo0+yTHoEa+DjEsgERFRGOHtHzta/jZg/RQ4ANw1dCK+rzyIeE083rz6TaRHh+mkJWoxm9OFIyVmHDxjwsEioyd0FplQarI1er5WKceFydHo623dzEqOQVZyNOKiuNoAEYW+TnX9phZjuJTCZ/cCu9bCEtMNt/bug4OVh9EzpifeuOoNxGpipa6OJFBmtiGvyIRcbwvnwSITDhWbYKuz1mZdyTEaT9hMiUZf73jOXgl6TiAiopDS6a7f1CIMl1KwW4CXLwIqjqNk8A24xXUcRZYiDE0cilcmvgK1nOsmkudWlcfLLPVaOY0oLK9p9HyFTMAFiXrvGM4Yf/BMilFzAhERSaLTXb+pRRgupXLiB+CfVwMQceTalzDz15dhcpgwscdEPHPZM1wDk5pksjpwqNg3jtMbPM+YYLI5Gz0/VqdEnyTPBKKs5GhkpcTgwiQ9JxARUbvrlNdvOieGSyl9sQjYsRqITsGu61fhT9v+CqfbiVv734q/jPiL1NVRGPFNIPJ1qeeeMSKvyIRjZy1wuRv+J+6bQFR3iaSs5Bh05wQiIgqiTnv9pmYxXErJXg2suRgoPwoMvhmfDJ6MRd8uAgAsGrUIN/e9WeICKdxZHZ4JRHlFtV3ruWdMOGs+9wQiX/d6zwQdEqM1kDN0ElErddrrNzWL4VJqBTuBdZMAiMBN7+IV20m88OMLECBg5eUrcUX3K6SukDqhs74JRN6WzrxzTCBSyAQkGzRIi9UiLU7rea6znRqrhUYpb/S9RBS5OvX1m5rEcBkKvnoY+OFFQJ8Ece52PPa/l/DeofegkWuQMykHg7oOkrpCigBOlxvHy6pxsMjoDZ4m5BUbcabSCmcjXev1JehV/qBZP3h2i9PCoFVyYhFRhOn0129qFMNlKHBYgX9cApw9BAz8A5zXrsHd/7kb35761rMG5lVvIj2Ga2CSNFxuEcVGK05X1uBUZQ1OVnieT1fW4JR3u9ruOufnRKnknuBZL3T6gii73ok6n05//aZGMVyGipN7gZzxgOgGbngD1ZnjcesXtyK3PBc9YnrgjaveQJwmTuoqiRoQRRFVNQ5/6DxVUeMPor4QetZsP+fnBHS91+1+j6ttDWXXO1F4iYjrNzXAcBlKvn4U+O5ZQJcAzNuJszLglk9vwWnLaQzpOgSvTHwFGoVG6iqJWs3qcDUMnhW1AbSoquVd7/5ud18XvDeEsuudKPREzPWbAkR0uHTbbHBVVECZnBy0zzwvThvwj8uA0lyg/7XAH17D0cqjmPH5DJjsJkzoMQF/v+zvXAOTOh2XW0SJyeoPnCcbCaGt7Xr3hVBf13titAbxehWiVHIGUKIOwnAZmSI6XJ5ZuhSmL75E6jNPQ3/JJUH73PNy+kfglSsB0QVc/09gwO+xu2g3/rT5T3C4HZjRbwbuG3mf1FUSdaj6Xe91x3v6QmhLut4BQK2QIUGvRnyUCl30KnSJUnufVeiiV3ufa7fZFU/UdgyXkSliw6W7pgYnps+A9ddfAUFAwtz/Q8K8eRDkIXAh+c8TwLanAW08MG8noE/EZ8c+w/3f3g8AuH/k/Zjeb7rERRKFFqvD1WiXu2/7rNkGq6PxpZaaE6WSI94bQhP0Km8orRNC/eHUE1h5f3eiWgyXkSliwyXg6RYvfvJJVL7zLgBAN2Y00p55BoqEhKB9R5s47cArlwPFvwBZ1wDT3gQEATk/52DlvpUQIOC5cc/hyh5XSlsnUZiptjtRZrbjrNmGcovds22xodxsR5klcH+ZxQaHq/X/e4zRKALCZ3y9UJoQpfKH1TidEgo5wyh1XgyXkSmiw6VP1cef4MySJRCrq6Ho2hVpzz0L3YgRQf+eVjnzP0/AdDuB63KAgddDFEU8sfMJbMjbALVcjVcnvoohiUOkrZOokxJFESabJ4yWW2w4a7YHbls8256wakdFtb3RW202RxCAWK2yiZbQhi2kBq2St+eksMJwGZkYLr1sR4/i5Pz5sB85CsjlSLxnAeJvuw2CTMJWha1PAVuXAZpYT/d4dDKcbicW/HcBvjn5DWLVsXjz6jfRI6aHdDUSEQDA7faMCy3zBs4yix1lZpv32Y5yb8uoJ5R6wmhr/+8rlwmI0ykRq1MhXqdCrE6J+CiV53VU7f64KCXidCrE6VQMpCQphsvIxHBZh7u6GmeWLoXxo48BAPrLL0fqk8shNxja7Tub5XIAr14JnPkJuPAq4KZ3AEFAtaMas7+cjQNlB9A9ujveuPoNxGvipamRiNrE6XKjotrh7Ya34azFjnJv+Dxrrm0V9YVUo9XZpu+RCYBBq0RclMofOOMaC6VRKn9wjdWyu56Cg+EyMjFc1iOKIio3/gvFTzwB0W6HMi0NaStXQjtwQLt+b5OKDwD/uBRwO4Cpa4AhNwEAztacxfTPpuOU+RQGdR2EVye+Cq1CK02NRNTu7E43yr2tnpXVdpRX21FR7UCFtxW00htUfccqLQ6YbG0LpIBn7GhtAPW2kupUdUJqncDqbSlVMpBSPQyXkYnhsgk1v/6KUwvugaOwEIJSiaQHFyH2xhulWR/v2xXAlscAtQGYtwOISQUAHKs6hhmfzYDRbsQV6Vfg3pH3Ik2fxjX8iAiAJ5BW1thRYXGgotruDaK12+X1Q6nF3uYWUgCIVisQG6X0dtkHhtLYKG+XvTeUGrRKRGsUiFIp2G3fiTFcRiaGy2a4jEacfvBBmL/eAgCImTwZKY89CllUVIfV4CnECeRMAE7vAy6YANzyL89MAAB7i/fijq/ugMPtAABEq6KRFZ+FrPgs9I3vi6z4LGQYMqCQKTq2ZiIKS06XG5U1DlR6W0Zrg6fDH0D9AdUbUitrHK0eP+ojEwC9WoFojSdsxmiViNHUee19rnvcs9+zL0ajhEYp4z+qQxTDZWRiuDwHURRR/tp6lKxYATidUPXqhW7Pr4Q6M7ND60DJQU/3uMsG/PYlYNgM/6FtJ7dh1f5VOFxx2B8y61LL1ciMzURWF0/g7BvfF5lxmbyVJBEFhcstwlhTN3A6vK2igaG0sk4orapxtGmpp8YoZII/gMZoFYhWKwNfa3yB1RdWfcdrw6paEQJrHHdCDJeRieGyhar37cOpexbCWVwMQatFytIlMPzudx1bxPfPA5sfAdQxwNwfgNj0gMMOlwPHqo4htzwXuWW5OFh+EAfLD6LaWd3go+SCHBmGjIBWzj7xfWBQSzR5iYgiiiiKsDndMNY4YLQ6YbI6YLI6YfQ++1/X+PZ79tU912R1oJWrPzVJpZAhprGW0iZaTuse06sV0DOgNioUrt/U8RguW8FZXo7T994Hy/ffAwBi//AHJD38EGRqdccU4HYB6yYBJ3cDvS4HZnzg7x5v8i2iG4WmQuSW5+JgmSds5pbnotxa3uj5afq0gMDZt0tfdNV2ZZcTEYUcURRhsbsaCaLNB9W6x8znMempPpVchii1HHqNAnq1Enq13Bs862yrld7j8ia2PQ95JxmHGirXb+pYDJetJLpcOPvyGpxdtQoQRaj79kW351dC1b17xxRw9jCw5mLAaQWuWQmMmN3qjxBFEaU1pcgty/WETm8L5ynzqUbPj9fE+8dv+rrW06PTIRM4M5SIwpvLLcJsqxs8mwim/lZTbwtqnaBa43AFvS6tUh4QNn2to41uqxWIUisCWlF9+3UquaSNA6F0/aaOw3DZRubvv8fpv94LV0UFZHo9UpY9gZiJEzvmy7evAr58EFDpPd3jccFZRL3KVoW88ryAwHms6hjcYsP7MUcpo9Anro+nhbOLZxxnr9heUMqUQamFiChcOF1uWOwuWGyellCT1enfNludMNmcTR4z2wIfdmfD/9+eD5kARKnqBM5mQumUwalIjQ3uknaheP2m9sdweR4cxcU4dc9C1OzbBwCInzULiX/9CwRlOwcstwt4bTJQsB3IuBSY8SHQTncSsjqtOFxx2DOO09u1frjyMGwuW4NzlTIlLoi9AH279PV3q18YdyF0Sl271EZE1NnYnC5YbJ6g6uu2t9g8AdUTRh0w21z+bYvN5T3m2fYEWAcsdlerb0f677kXYXiPuKD+PKF6/ab2xXB5nkSHAyXPrUT5unUAAO2QIUh77lkoU1La94vLjnq6xx3VwNV/B0bd0b7fV4fT7UR+Vb5//ObB8oM4WHYQJoepwbkCBPSI6eHpVq8zWz1WE9th9RIRRRpRFGF1uGHyBlBPC6oDZqsTFnu9FlXv9l8m9kEaWy4pCBgug8T09dc4vehBuE0myGNjkfrMM9BfcnH7funOtcDn9wJKHTD3eyC+V/t+XzNEUcQp8ykcLD+IA2UH/N3qpTWljZ6fHJUcsBZn3/i+SI5K5sQhIqJOJByu3xR8DJdBZC8sxMn582E7kAsIAhLmzkXCvD9DkLfT8hRuN/D6b4Hj3wLdL/Isrq7Wt893tdHZmrP+oOlbHqnAVNDoubHqWPSJ64MUfQoSdYlI0iUhUZfof8Rr4jmJiIgojITL9ZuCi+EyyNw2G4qXLUflhg0AgKiLxiD1mWeg6NKlfb6w4jiw+iLAYQEEOZA8EOg+GkjP9jx7bxUZSsx2c23g9HarH6s8BqfY/JIgCpkCXbVdA4Jn3QCapEtCYlQi1PIOWhqKiIiaFU7Xbwoehst2UvXxxzjzyBKINTVQJCYi7blnoRs+vH2+LPcT4IsHgKrChsdiuwPpo4Hu2UD3MUDXvu02+ed82Fw2HKk8giMVR1BcXYyS6hL/c0l1CcpqyiCiZX9VDWpDYOCss+17HauOZRc8EVE7C8frN50/hst2ZDtyBCfnL4D96FFALkfiwnsQf9tt7Rdqqk4CBTuAwp2emeTFvwL1lxFSG4D0kd7AORpIGw6oQn82t8PtQFlNGYosRf7AWT+AllSXwOqytujzVDIVuuq6Nuh6r/9aJVe1809GRNR5hev1m84Pw2U7c1ssOLP0URg//hgAoL/iCqQuXwa5oQNus2g1Aqf2AAXesHlyj6f7vC6ZAkge5Ama3Ud7Qmd0UvvX1g5EUYTRbmwQPusH0KbuTtSYeE18QNhsrDU0RhXDVlAiokaE8/Wb2o7hsgOIoojKDRtQ/MQyiA4HlN26IW3lSmgH9O/YQlxOoPiX2pbNgp2A6XTD8+J61rZsdh8NJPQJya70trK77CitKa1t+bQ03hJqd9tb9HkauQZddV39gTNZl4xEXSLiNHGIU8chVhOLOHUcDGoDtAotgygRRYxwv35T2zBcdqCaX37FqQUL4Dh5EoJSiaQHFyH2xhulCxui6Bmn6WvZLNzp6UqvP7ZREwukj6pt2UwbBiiDuxZaqBFFEZW2yka73uu+rrRVtupz1XI1YtWxiNPEeZ694TNWHRu43/scq46FRqFpnx+SiKiddZbrN7UOw2UHc1VV4fSDD8G8ZQsAIOaaa5Dy6FLIoqIkrszLWgWc3O0Zu1mwAzi117NQe10yJZAyOLArXd9VmnolZnPZAoJnSXUJiixFKK0pRaW1EhW2Cv+zw+1o03doFdpGw6dBbQhoGa17nGNFiSgUdKbrN7Ucw6UERFFE+bp/ouTZZwGXC6revdHt+ZVQX3CB1KU15HIART8HdqWbixqeF9/LMxvdtwRSwoUAu3/9RFFEjbMmIGxWWCtQaav0P/se/tfWynMuz9QUnUJX2/rZSPhsLKjyvvBEFGyd7fpNLcNwKaHqvXtx6p6FcJaUQNBqkfLoUhh++1upy2qeKAKVJwK70kty0aArXRtXuwRS+mggdSigZPdua4iiCLPDjEqrN3TaAsNo3ecqWxUqbJ5nl+hq0/fplfpGQ2e0MhpRyij/Q6fUQa/UN9hmaykR1ddZr9/UPIZLiTnLynD63nth+WE7ACD2hhuQ9NCDkKnDaCHwmkpvV7q3ZfPUXsBZE3iOXOUJmL6WzfRsICpBknI7M7fohsluatgiam06nFbZqlq8hmhzFDJFQOiMUkQhShXleVa27qGRazjxiagT6MzXb2oaw2UIEF0unF39Ms6uXg2IItT9+qLbypVQde8udWlt47R7utILtgOFOzyB01LS8LwumbUtm91HA10uYFe6BFxuF0x2U5Ph0+www+KwoNpRDbPDjGpHNSwOi//R0rVFW0MmyBqEU18rqU6pQ5QyKmA74NHI+3jbUCJpdPbrNzWO4TKEmL/7HqfvvReuigrIoqORunwZosePl7qs8yeKQEV+7SShwp1A6cGG5+m6AN1GAV0v9IzhjO8FxGUAMWmdaimkzsbpdqLaWe0Jn3YzLE5LQPisG0x92wHHnYHnBaMVtT6dQucPmjqFDlqFFjql91mh8+9v7Nl3rk4RuE8hUwS9TqLOJlKu3xSI4TLEOIqKcOqehaj58UcAQPzs2UhceA8EZSebbFFdDhTuqm3ZPLUXcNkaP1eu9qy9GZ8RGDrjMzy3t5R3sj+bCOYW3bA6rQ2CaMBrpwVmuxnVzuoGIbZ+oG3rhKiWUMvVzQbQZkNqE+cqZUoOB6BOJZKu31SL4TIEiQ4HSlY8i/LXXgMAaIcNQ9qzK6BMTpa2sPbktAFnfgJO7QPKj3laOsuPARUngOaW8BHkQGx6vdDp2+7R6dfjpKaJogi72+4Joo5qT+uqt4W1qecaZ805z23rhKmWUAgKaJVNtKYqdNAqtdAqtNDINdAoNAHbGoWmwbZWofW/1so9ra0Mr9SRIu36TR4MlyHMuHkzzix6EG6zGfK4OKT+/Rnox46VuqyO5XZ57plefqxO6PQGz/L8hhOH6otJ8wbNnrWhMz7DE0I1kfN3iYJDFEU43I6GobO5kNrEuXXPsTXVah9kMkHWdDD1BlC1Qh0YTOuer9BALVc3eK9Wrg34HC5rRT6Rev2OdAyXIc5eUICTCxbAdiAXEAQk/PnPSPjzXAhyudSlSU8UAVNRYEunL3SW5wO2qubfH9U1sKWzbre7No6Ti6jDON3ORltNGwupVqcVNc4aWF1WWJ2eR42rBlanFTanDVaX97jT6t92i+4O/XnkgrxhMK3XqqpWqKGSqaCSq6CUKaGSe7ab2xdwXK6s3S/zvq5znJO4QkMkX78jGcNlGHDbbCh+YhkqN24EAERdNAapf/87FPHxElcWwkTRM66zQej0blefbf79akNg2Ky7rU9i8KSwIYqiJ7x6A6gvdNbd9ofReq9tLlvDIFvvtW+7xlnTLpOx2kohUzQbPuuGV7VcXfu6BeFVLVf7j6vlav9n1N2u+xzJQTfSr9+RiuEyjFR99BHOLFkKsaYGiqQkpD33LHTDhkldVniyGut1sR8DKo57no2nmn+vUlc7ocgXOn0toIZugIytyhR5fEMG6raaNgijdfbZXXbPw233bzvcjgb7fK8dLkfg/nr72np71Y6glClbFEKbOqaWq1sUZEMx3PL6HZkYLsOM7fBhnJy/APZjxwC5HIl/+QviZ9/KQfrB5KjxTCQKGOfp3a4sBJqb0CFTeiYSxffyzGQ3dAMM6d7tdE+rJ5dVIgo6X7htKpwGhNdm9vkCq81la/Z4/c/3nW9z2WBz2Tp8KEJzWhpu7xl2D3rF9grqd/P6HZkYLsOQ22LBmSVLYfzkEwCAfvyVSF22DHL+2bQ/lwOoLPC0eNbvcq/IB1z25t8vV3kmGcWme8KmIb12Ozbdc0wRRndnIqJGOd3OgLDp225sX/3tpo419xl2lx02t+fZ6rS2aYjC21e/jYFdBwb1z4HX78jEcBmmRFFE5YYNKH5iGUSHA8rUVOivuALqPhdCk5UFdWYmZBrey7tDuV2A8XRt6KwsBKoKPbPdKws93e3nXMZG8LRuxtYPnnVaQTnLnYiaIYoinKKzxYHW93xF9ysQrwnuWH5evyMTw2WYq/nlV5yaPx+OU/XGCcpkUPXs6QmbfbL8oVORnMwudKm4nIDpjCdwVhYCVQW1wdO371xLKwGAxgAYutdp/ezm3fbui+rKCUdEFBJ4/Y5MDJedgMtshnnLFlgP5sGWdxDWg3lwlZc3eq7MYIDmwguhzsqCJqsP1Bf2gTrzArZyhgJRBKrLPN3uVSfrhNBC775CoKbi3J8jV9cJnHXGe/pex6TyrkZE1CF4/Y5MDJedkCiKcJ09Wxs28w7BdvAgbPn5gLOR2+HJZFBlZEDT50Ko+3hDZ58+UCQlsZUz1NjMdYJnQWAArTrp6ZY/11grQQZEpwQGTkO3wBCqiuqQH4eIOjdevyNTm8LlqlWr8Mwzz6CoqAiDBw/Giy++iFGjRjV67iuvvILXX38dv/zyCwBg+PDhWLZsWZPnN4Z/OYPDbbfDfvSoJ3QePAjroTzYDubBVdF4a5jcYIA6K6u2az2rD9QXXACZmhNOQpbL4RnbWbervaru9smm7+Felza+NnhGJ3vGgUZ19TzrEz2PqERAyRZvImoar9+RqdXhcsOGDZg5cybWrFmD7OxsrFy5Ev/617+Ql5eHxMTEBuffcsstGDt2LC666CJoNBo89dRT+OCDD/Drr78iLS2tRd/Jv5ztRxRFOEtKYTuUB+vBg7AdzIPtUB5sx/IBVyOTT+RyqDJ6esdx9vG2cmZBkdiVrZzhwO0GLKX1Ame953Pd2agutQHQd60XPn2vEwODqELVfj8XEYUkXr8jU6vDZXZ2NkaOHImXXnoJAOB2u5Geno677roLDzzwwDnf73K5EBcXh5deegkzZ85s0XfyL2fHc9tssB05AlveIf84TtvBg3BVNR485LGxnnGcffr4Q6fqggsgUzFQhB1rVeBEI3MxYC7xPCwltdutvR+2JrZhy6dvu244jUrgmFCiToLX78ikaM3Jdrsde/fuxaJFi/z7ZDIZxo8fj+3bt7foM6qrq+FwOBDfzK0LbTYbbLbaC5fRaGxNmRQEMrUa2v79oe3f37/P08pZ4ulS947jtOblwZ6fD1dlJap37ED1jh21HyKXQ90rA+o6s9XVffpA0ZWtnCFNY/A8kvo3fY4oekKoP3AWA+ZSz3PdAOo77nYC1krP42zeuWvQdWk6fNZtGY1K4B2RiIhCTKvC5dmzZ+FyuZCUlBSwPykpCQcPHmzRZ9x///1ITU3F+PHjmzxn+fLlePTRR1tTGnUAQRCgTEqCMikJ+ssu8+93W62wHTnqnTzkGcdpzcuDu6oKtsNHYDt8BPik9nPkcXFQZ/UJ6FpX9e7NVs5wIgiANtbz6Hph8+e63Z5QafaGUEtpI62h3nBqKfWsBVpd5nmU5p6jDpkniJ6rW16fBGjjGESJiDpAq8Ll+XryySfx7rvvYuvWrdA0s/TNokWLsHDhQv9ro9GI9PT0jiiR2kCm0UA7oD+0A+q1chYXB4zjtB7Mg/34cbgqKlC9fQeqt9dp5VQooM7IgLpPH6h69IAyvRtU3bpBmZ7uaenkLRPDl0wG6OI9j8Ss5s91u4Ga8sDw2VRrqOUsIHrHkFpKW1CI4GmR1cV7Jiz5nrVx3u24xo+porhuKBFRK7QqXCYkJEAul6O4uDhgf3FxMZKTk5t979///nc8+eST+PrrrzFo0KBmz1Wr1VBzRnJYEwQByuRkKJOTET1unH+/22r1tGb6xnHmeVs5jUbYDh+G7fDhhp+lUkHZrZs3cKZD2a0bVOme4KlM6wa5nsvmdBoymaerOyqh+W55wLMofXVZ0+Gzbld9TTkAsbZrHsdaXpNcFRg4dXF1XsfVO1YnlMo79N/uREQho1X/91OpVBg+fDi2bNmCqVOnAvBM6NmyZQvuvPPOJt/39NNP44knnsCXX36JESNGnFfBFN5kGg20AwdAO3CAf58oinAWFXlaOQ8fgaOwEPaThXAUnoTjzBmIdjvsx47BfuwYLI18pjw+3hM4vS2dqvRuUHpDqDI5CYKCF/lOSa4AopM8j3NxOTwL0FeXe4JmwHNF4HbdY26H537x5iLPozXUBs+wgfrBM6DFtF44VUezlZSIwl6bliKaNWsW/vGPf2DUqFFYuXIlNm7ciIMHDyIpKQkzZ85EWloali9fDgB46qmn8Mgjj+Dtt9/G2LFj/Z+j1+uh1+tb9J2cbRa5RKcTjqIiT+As9AbOUydhLzwJR2EhXJWVzX+AQgFlamq94OkJn6r0bpAbDB3yc1AYEkXAbmk8jDYIpXWera1Yyqk+mTKwm75BS2l87YQrTYwnwGpiAHUM1xylkMTrd2RqdZPOtGnTUFpaikceeQRFRUUYMmQIvvjiC/8kn4KCAsjqjI97+eWXYbfbcf311wd8zpIlS7B06dLzq546PUGhgMrbKhk1ZkyD4y6TCY6TJ2E/edITPE8W+oOn49QpiA4HHAUFcBQUNPr5spgYT/D0dbunp/uDpzIlBQInGUUuQQDUes8jtnvL3+dyegJmY8GzuZZSp9XTUmrxduu3llzlCZm+sOl/NjSx33eMAZWIgou3f6ROS3S74Swp8bZ61gmeJ0/CfrIQrtKzzX+ATAZFcpJnnGfd4NktDcr0dMjj47mkEgWPvbrp1tCaysCWUWsVYDUCNiNgM+Gct/xsqbYEVF849Z3DgEp18PodmRguKWK5q6vhOHUqIHDWbf0UrdZm3y/odLXd7d3SPOM8fSE0LQ2yZlZEIAoatxuwm2rDZsBzVSP7G9knRUBV6wGVHlDqAJUOUEZ5Zub7t3WeY/wHXFjj9TsyMVwSNUIURbjKyjzjPE+erB3v6e2CdxYVecbkNUNQqyHT6yGLivI+dJBH1Xld95g+CvLG9vtes3ue2lNrAqq1qpFzghxQ/YQ64VPnCaP+bW8Y9W37zjtXYPUdV6gZXDsAr9+RidNoiRohCAIUCQlQJCQAQ4c2OO622+E4dQqOk97A6R3n6Rn7WQi32QzRZoPLZoOrrOz8C1IqIdfp6gVSfW1orR9Io5oOroJGw+58CiST1U4UaqsWB1Tvtt0C2M2Ao9ozJMBh8e6rBpw13g8VPfsdja0TcZ4EWdOtpfWDa4MQW/+4vnafKoqL9VPEY7gkagOZSuVZ9D0jo8ExURThNpngNpngMlvgtvgeZv+2y1y77a57jne/q9qzX6zxXmQdDriqqpq8t3vripfVCac6yKJ84bPx4CrTRUGm1UCm1ULQaiGr8/C9ZmCloARUH7fbGzq9wdJeXfvabqlzrP6+6qYDq+9zXN5bC4veMGw3nX+99Sm0dcJmveAZ8LqRbbW+8WNyZfDrJGonDJdEQSYIAuQxMZDHxOB8LweiywV3dbU/dAYG08D9vgDraiq0Vld7uvLdbn/4DSYhIHRqINPqGmzLtBrvebp62w2PybRaCDodZBoNw2ukkclqZ+oHm8vZRGCtu898jkBbN8R632c3eQIr4Gl5ddYA1eeYNNgaclUrw2oLgqxCw6EB1C4YLolCmCCXQx4dDXl09Hl/luh2Q6ypaX1rak0N3DXVEKtr4LZa4a6pgVhdDbfVCtFmq/38mhq4amrgOu9KGyEInuCp8YROmU4LQdOwBbXZYKvTQqbTec7VeVtkdd73cKH9yCFXAPIgtbDWJYqA01bb3e8LpQ22mztmafjaZfd8vssO1Ng9KwoEiyALDJ2/fwVIGxa8z6eIxf+jEkUIQSaD4O32DhbR5YK7xgrRWuMJodU1TW67rTUQG9uu8b72b1s94bWmBqLde2EVRYjV1XBVV7dLeBVUKk/w1NUJnr4QqtVCFlUvlPq3fc86CFpd4D6tFoKSXZkRQxA8yzApNUBUl+B9rtNep3u/mRDa0rDqa30FPC2tNu9YWKIgYrgkojYT5HLPvd3b6f7u/vBa42kpdVfXBGy7a6oh+re9YbaR7YDWV29wdVdXAy5PVBXtdrjsduBcd3xqJUGp9IZWXW1QrRtYdTpPy2rdY74W1rrH6gZWrRaCSsVhApFCofI8tHHB+0y3K7DL3xc8Ey4M3ndQRGO4JKKQ1Z7hVRRFiHY73NXV/pZSd3W1J5BWV3tDaJ1jlrrneI/V3VfnGJxOz3d4J2IhGBOx6hIEz1JXarVnPKpGDZnKsx2wT63xnKdRQ1DX2adRe8ayqrzHNL7zNBDUGsjUqsB9Gg0EpZKBtrOQyT33sVef/3AbosYwXBJRRBLqBDTEBbFVCPCH1oAwWl0Dd7XFOxygfoitc6xBiK3xB2DR4fB+gQjRaoXLag1+cG2KIHjCq0oVGF59gVatDgyv3mOCWhUYaNUayDRqQN7K5XrasoRmq5dxbv2XCAqFd3UFvWfZr+hoz5JfajXDOEUshksioiATVCrIVSrIY2OD+rmi3Q63zeYZCmCzQbTZ/BOrRKsVbqsNos17zLcd8GyD22YNPGa1wm33nu/73DrP/oAmiv5JWx0WaMOZQuFZ4kuv9zyi9Z6bKPhe66O869PqIYuOrn1dN6jq9Z5hEAypFGYYLomIwoQvtCIIqwe0hCiKgMPRIHD6gm1AoPU+ewJvvfBqs0K02QP2iW536wtqQ8YSWvumVgY5Tyu1xbMKg9kMt9nsnTnuDM7atHI5ZHp9YFDVR0Guj248qOr1kEfXCbFResj1URB0OoZU6jAMl0RE1ChBEIAODrThTnS7PUMeLGZ/2HSZzZ7lvcymeq/NnrVpzWa4Td5zLbXH4HYDLhfcVVVwn29I9d08oZkW1LhbboYqPT04fxAU0RguiYiIgkSQySDXR3kmoiUltflzRN8wBHNtSK0fTF1mU21IrRdM3SaT54YKZrNnVYQ6N09wNvGdMb+ZBDBcUhAwXBIREYUYQRD8S1ghMbHNnyN6J3/Vb0Gt33rqNpuhSEkN4k9AkYzhkoiIqJMSfHe30mqh6NpV6nIoQsikLoCIiIiIOg+GSyIiIiIKGoZLIiIiIgoahksiIiIiChqGSyIiIiIKGoZLIiIiIgoahksiIiIiChqGSyIiIiIKGoZLIiIiIgoahksiIiIiChqGSyIiIiIKGoZLIiIiIgoahksiIiIiChqF1AW0hCiKAACj0ShxJURERNRSvuu27zpOkSEswqXJZAIApKenS1wJERERtZbJZILBYJC6DOogghgG/5xwu904ffo0oqOjIQiC1OWEHKPRiPT0dBQWFiImJkbqcgj8nYQa/j5CC38foaU9fx+iKMJkMiE1NRUyGUfiRYqwaLmUyWTo1q2b1GWEvJiYGP6POsTwdxJa+PsILfx9hJb2+n2wxTLy8J8RRERERBQ0DJdEREREFDQMl52AWq3GkiVLoFarpS6FvPg7CS38fYQW/j5CC38fFGxhMaGHiIiIiMIDWy6JiIiIKGgYLomIiIgoaBguiYiIiChoGC6JiIiIKGgYLsPY8uXLMXLkSERHRyMxMRFTp05FXl6e1GWR15NPPglBELBgwQKpS4lYp06dwvTp09GlSxdotVoMHDgQe/bskbqsiOVyubB48WJkZGRAq9Wid+/e+Nvf/sb7TneQbdu2YcqUKUhNTYUgCNi0aVPAcVEU8cgjjyAlJQVarRbjx4/H4cOHpSmWwhrDZRj75ptvMG/ePOzYsQObN2+Gw+HAxIkTYbFYpC4t4u3evRv/+Mc/MGjQIKlLiVgVFRUYO3YslEolPv/8cxw4cAArVqxAXFyc1KVFrKeeegovv/wyXnrpJeTm5uKpp57C008/jRdffFHq0iKCxWLB4MGDsWrVqkaPP/3003jhhRewZs0a7Ny5E1FRUZg0aRKsVmsHV0rhjksRdSKlpaVITEzEN998g0svvVTqciKW2WzGsGHDsHr1ajz++OMYMmQIVq5cKXVZEeeBBx7A999/j2+//VbqUsjrmmuuQVJSEnJycvz7rrvuOmi1Wrz55psSVhZ5BEHABx98gKlTpwLwtFqmpqbiL3/5C/76178CAKqqqpCUlITXXnsNN954o4TVUrhhy2UnUlVVBQCIj4+XuJLINm/ePEyePBnjx4+XupSI9tFHH2HEiBH4wx/+gMTERAwdOhSvvPKK1GVFtIsuughbtmzBoUOHAAA//fQTvvvuO1x11VUSV0b5+fkoKioK+P+WwWBAdnY2tm/fLmFlFI4UUhdAweF2u7FgwQKMHTsWAwYMkLqciPXuu+9i37592L17t9SlRLxjx47h5ZdfxsKFC/Hggw9i9+7duPvuu6FSqTBr1iypy4tIDzzwAIxGI7KysiCXy+FyufDEE0/glltukbq0iFdUVAQASEpKCtiflJTkP0bUUgyXncS8efPwyy+/4LvvvpO6lIhVWFiI+fPnY/PmzdBoNFKXE/HcbjdGjBiBZcuWAQCGDh2KX375BWvWrGG4lMjGjRvx1ltv4e2330b//v2xf/9+LFiwAKmpqfydEHUi7BbvBO6880588skn+O9//4tu3bpJXU7E2rt3L0pKSjBs2DAoFAooFAp88803eOGFF6BQKOByuaQuMaKkpKSgX79+Afv69u2LgoICiSqie++9Fw888ABuvPFGDBw4EDNmzMA999yD5cuXS11axEtOTgYAFBcXB+wvLi72HyNqKYbLMCaKIu6880588MEH+M9//oOMjAypS4poV155JX7++Wfs37/f/xgxYgRuueUW7N+/H3K5XOoSI8rYsWMbLM116NAh9OjRQ6KKqLq6GjJZ4GVHLpfD7XZLVBH5ZGRkIDk5GVu2bPHvMxqN2LlzJ8aMGSNhZRSO2C0exubNm4e3334bH374IaKjo/3jYgwGA7RarcTVRZ7o6OgG412joqLQpUsXjoOVwD333IOLLroIy5Ytww033IBdu3Zh7dq1WLt2rdSlRawpU6bgiSeeQPfu3dG/f3/8+OOPePbZZ3HbbbdJXVpEMJvNOHLkiP91fn4+9u/fj/j4eHTv3h0LFizA448/jszMTGRkZGDx4sVITU31zygnajGRwhaARh///Oc/pS6NvC677DJx/vz5UpcRsT7++GNxwIABolqtFrOyssS1a9dKXVJEMxqN4vz588Xu3buLGo1G7NWrl/jQQw+JNptN6tIiwn//+99GrxmzZs0SRVEU3W63uHjxYjEpKUlUq9XilVdeKebl5UlbNIUlrnNJREREREHDMZdEREREFDQMl0REREQUNAyXRERERBQ0DJdEREREFDQMl0REREQUNAyXRERERBQ0DJdEREREFDQMl0REREQUNAyXRERERBQ0DJdEREREFDQMl0REREQUNAyXRERERBQ0/w/bzIUeh7B9agAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizers = (\n",
    "    SGD(0.01),\n",
    "    NAG(0.01, 0.9),\n",
    "    Adagrad(0.01),\n",
    "    Adam(0.01, 0.9, 0.99)\n",
    ")\n",
    "\n",
    "y_s = list()\n",
    "for optimizer in optimizers:\n",
    "    perceptron = Perceptron(layers=(784, 18, 10), optimizer=optimizer)\n",
    "    perceptron.train(\n",
    "        training_data=training_data,\n",
    "        test_data=test_data,\n",
    "        epochs=epochs,\n",
    "        batch_size=70,\n",
    "        loss_func=CategorialCrossEntropy(),\n",
    "        is_loss_funcs_plot_needed=False\n",
    "    )\n",
    "    y_s.append(perceptron.get_loss_values())\n",
    "    score, _ = perceptron.predict(test_data=test_data)\n",
    "    print(f'Optimization method: {str(optimizer)}')\n",
    "    print(f'Accuracy of guessed numbers: {score}%')\n",
    "\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    x, y = range(1, epochs + 1), y_s[i]\n",
    "    plt.plot(x, y, label=str(optimizer))\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оптимизация гиперпараметров (число слоёв, число нейронов в слое)\n",
    "### Использование для этой цели генетического алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m     best_individual \u001b[39m=\u001b[39m population[np\u001b[39m.\u001b[39margmax(fitness_values_individuals)]\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m best_individual, fitness_values_individuals[np\u001b[39m.\u001b[39margmax(fitness_values_individuals)]\n\u001b[0;32m--> 106\u001b[0m x, y \u001b[39m=\u001b[39m genetic_algorithm()\n\u001b[1;32m    107\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBest individual: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 50\u001b[0m, in \u001b[0;36mgenetic_algorithm\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m fitness_values_individuals_hist \u001b[39m=\u001b[39m {}\n\u001b[1;32m     48\u001b[0m fitness_values_individuals \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 50\u001b[0m \u001b[39mfor\u001b[39;00m genome, fitness_value \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(population, np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(fitness_func, population)))):\n\u001b[1;32m     51\u001b[0m     fitness_values_individuals_hist[\u001b[39mstr\u001b[39m(genome)] \u001b[39m=\u001b[39m fitness_value\n\u001b[1;32m     52\u001b[0m     fitness_values_individuals\u001b[39m.\u001b[39mappend(fitness_value)\n",
      "Cell \u001b[0;32mIn[24], line 28\u001b[0m, in \u001b[0;36mfitness_func\u001b[0;34m(genome)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfitness_func\u001b[39m(genome):\n\u001b[1;32m     27\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 28\u001b[0m     accuracy \u001b[39m=\u001b[39m train_and_evaluate(genome)\n\u001b[1;32m     29\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     30\u001b[0m     completion_time \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[24], line 15\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(genome)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_and_evaluate\u001b[39m(genome):\n\u001b[1;32m     14\u001b[0m     network \u001b[39m=\u001b[39m create_neural_network(genome)\n\u001b[0;32m---> 15\u001b[0m     network\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     16\u001b[0m         training_data\u001b[39m=\u001b[39;49mtraining_data,\n\u001b[1;32m     17\u001b[0m         test_data\u001b[39m=\u001b[39;49mtest_data,\n\u001b[1;32m     18\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     19\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m70\u001b[39;49m,\n\u001b[1;32m     20\u001b[0m         loss_func\u001b[39m=\u001b[39;49mCategorialCrossEntropy(),\n\u001b[1;32m     21\u001b[0m         is_loss_funcs_plot_needed\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     accuracy, _ \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39mpredict(test_data\u001b[39m=\u001b[39mtest_data)\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m accuracy\n",
      "Cell \u001b[0;32mIn[16], line 72\u001b[0m, in \u001b[0;36mPerceptron.train\u001b[0;34m(self, training_data, test_data, epochs, batch_size, loss_func, is_loss_funcs_plot_needed)\u001b[0m\n\u001b[1;32m     70\u001b[0m     n \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     71\u001b[0m loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m n\n\u001b[0;32m---> 72\u001b[0m score, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(test_data\u001b[39m=\u001b[39;49mtest_data)\n\u001b[1;32m     73\u001b[0m \u001b[39m# print(f'Epoch {epoch}\\{epochs}\\nloss: {loss: .2f}, accuracy: {score: .2f}%')\u001b[39;00m\n\u001b[1;32m     74\u001b[0m x\u001b[39m.\u001b[39mappend(epoch)\n",
      "Cell \u001b[0;32mIn[16], line 92\u001b[0m, in \u001b[0;36mPerceptron.predict\u001b[0;34m(self, test_data)\u001b[0m\n\u001b[1;32m     90\u001b[0m score, loss, n \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[39mfor\u001b[39;00m test_image, test_expected \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(test_data[\u001b[39m'\u001b[39m\u001b[39mtest_images\u001b[39m\u001b[39m'\u001b[39m], test_data[\u001b[39m'\u001b[39m\u001b[39mtest_expected\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m---> 92\u001b[0m     predicted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeedforward(test_image\u001b[39m.\u001b[39;49mreshape(\u001b[39m784\u001b[39;49m, \u001b[39m1\u001b[39;49m))[\u001b[39m1\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     93\u001b[0m     predicted_label \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(predicted)\n\u001b[1;32m     94\u001b[0m     expected_label \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(test_expected)\n",
      "Cell \u001b[0;32mIn[16], line 44\u001b[0m, in \u001b[0;36mPerceptron.feedforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers)):\n\u001b[1;32m     43\u001b[0m     weighted_input \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[i], outputs[i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbiases[i]\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[i], \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivate(weighted_input, \u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivate(weighted_input, \u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m     weighted_inputs\u001b[39m.\u001b[39mappend(weighted_input)\n\u001b[1;32m     46\u001b[0m     outputs\u001b[39m.\u001b[39mappend(output)\n",
      "Cell \u001b[0;32mIn[16], line 29\u001b[0m, in \u001b[0;36mPerceptron.activate\u001b[0;34m(self, x, activation)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mactivation should be \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m activation \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu(x)\n\u001b[1;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mapply_along_axis(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax, \u001b[39m0\u001b[39m, x)\n",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m, in \u001b[0;36mPerceptron.relu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrelu\u001b[39m(x):\n\u001b[1;32m     18\u001b[0m     \u001b[39m#return 1 / (1 + np.exp(np.clip(-x, a_min=-100, a_max=100)))\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mvectorize(\u001b[39mlambda\u001b[39;49;00m x: x \u001b[39mif\u001b[39;49;00m x \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m0\u001b[39;49m)(x)\n",
      "File \u001b[0;32m~/Documents/NeuralNetworks/venv/lib/python3.9/site-packages/numpy/lib/function_base.py:2372\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_stage_2(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   2370\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m-> 2372\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_as_normal(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/NeuralNetworks/venv/lib/python3.9/site-packages/numpy/lib/function_base.py:2365\u001b[0m, in \u001b[0;36mvectorize._call_as_normal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     vargs \u001b[39m=\u001b[39m [args[_i] \u001b[39mfor\u001b[39;00m _i \u001b[39min\u001b[39;00m inds]\n\u001b[1;32m   2363\u001b[0m     vargs\u001b[39m.\u001b[39mextend([kwargs[_n] \u001b[39mfor\u001b[39;00m _n \u001b[39min\u001b[39;00m names])\n\u001b[0;32m-> 2365\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize_call(func\u001b[39m=\u001b[39;49mfunc, args\u001b[39m=\u001b[39;49mvargs)\n",
      "File \u001b[0;32m~/Documents/NeuralNetworks/venv/lib/python3.9/site-packages/numpy/lib/function_base.py:2453\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2450\u001b[0m ufunc, otypes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ufunc_and_otypes(func\u001b[39m=\u001b[39mfunc, args\u001b[39m=\u001b[39margs)\n\u001b[1;32m   2452\u001b[0m \u001b[39m# Convert args to object arrays first\u001b[39;00m\n\u001b[0;32m-> 2453\u001b[0m inputs \u001b[39m=\u001b[39m [asanyarray(a, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args]\n\u001b[1;32m   2455\u001b[0m outputs \u001b[39m=\u001b[39m ufunc(\u001b[39m*\u001b[39minputs)\n\u001b[1;32m   2457\u001b[0m \u001b[39mif\u001b[39;00m ufunc\u001b[39m.\u001b[39mnout \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "training_data['training_images'] = training_data['training_images'][:2000]\n",
    "training_data['training_expected'] = training_data['training_expected'][:2000]\n",
    "test_data['test_images'] = test_data['test_images'][:2000]\n",
    "test_data['test_expected'] = test_data['test_expected'][:2000]\n",
    "\n",
    "def create_neural_network(genome):\n",
    "    # genome[0] - количество слоев, genome[1] - количество нейронов в промежуточном слое\n",
    "    network = Perceptron(layers=[784] +  genome[0] * [genome[1]] + [10], optimizer=SGD(0.01))\n",
    "    return network\n",
    "\n",
    "def train_and_evaluate(genome):\n",
    "    network = create_neural_network(genome)\n",
    "    network.train(\n",
    "        training_data=training_data,\n",
    "        test_data=test_data,\n",
    "        epochs=epochs,\n",
    "        batch_size=70,\n",
    "        loss_func=CategorialCrossEntropy(),\n",
    "        is_loss_funcs_plot_needed=False\n",
    "    )\n",
    "    accuracy, _ = network.predict(test_data=test_data)\n",
    "    return accuracy\n",
    "    \n",
    "def fitness_func(genome):\n",
    "    start_time = time.time()\n",
    "    accuracy = train_and_evaluate(genome)\n",
    "    end_time = time.time()\n",
    "    completion_time = end_time - start_time\n",
    "    \n",
    "    return accuracy / 10 if accuracy < 74 else 10 + (accuracy - 74) ** 4 - (completion_time / 60) \n",
    "\n",
    "def genetic_algorithm() -> tuple[np.ndarray, float]:\n",
    "    t, Np, k, Mp = 0, 4, 1, 10\n",
    "    # размер генома\n",
    "    n = 2\n",
    "    # формируем исходную популяцию с количеством особей Mp\n",
    "    population = []\n",
    "    Mp = 0\n",
    "    for i in range(1, 3):\n",
    "        for j in range (1, 5):\n",
    "            Mp += 1\n",
    "            population.append([i, j])\n",
    "\n",
    "    population = np.array(population)\n",
    "    fitness_values_individuals_hist = {}\n",
    "    fitness_values_individuals = []\n",
    "\n",
    "    for genome, fitness_value in zip(population, np.array(list(map(fitness_func, population)))):\n",
    "        fitness_values_individuals_hist[str(genome)] = fitness_value\n",
    "        fitness_values_individuals.append(fitness_value)\n",
    "\n",
    "    # print(population)\n",
    "    # print(fitness_values_individuals_hist)\n",
    "\n",
    "    fitness_value_population = np.sum(fitness_values_individuals)\n",
    "\n",
    "    while t != Np:\n",
    "        k = 1\n",
    "        while k < Mp:\n",
    "            # этап селекции (отбора особей) для последующего их скрещивания\n",
    "            q = fitness_values_individuals / fitness_value_population\n",
    "            new_population = [population[np.random.choice(len(population), p=q)] for _ in range(Mp)]\n",
    "\n",
    "            # этап скрещивания\n",
    "            Pc = 0.5\n",
    "            parent_indices = []\n",
    "            for i in range(len(new_population)):\n",
    "                r = np.random.random()\n",
    "                if r < Pc:\n",
    "                    parent_indices.append(i)\n",
    "\n",
    "            for parent1_index, parent2_index in zip(parent_indices[0::2], parent_indices[1::2]):\n",
    "                c = np.random.random()\n",
    "                parent1, parent2 = new_population[parent1_index], new_population[parent2_index]\n",
    "                parent1 = c * parent1 + (1 - c) * parent2\n",
    "                parent2 = (1 - c) * parent1 + c * parent2\n",
    "                \n",
    "            # этап мутации\n",
    "            Pm = 0.2\n",
    "            for i in range(len(new_population)):\n",
    "                r = np.random.random()\n",
    "                if r < Pm:\n",
    "                    p = np.random.randint(0, n, 1)\n",
    "                    if p == 0:\n",
    "                        new_population[i][p] = np.random.randint(1, 16)\n",
    "                    else:\n",
    "                        new_population[i][p] = np.random.randint(1, 33)\n",
    "\n",
    "            population[:] = new_population\n",
    "\n",
    "            fitness_values_individuals = []\n",
    "            for genome in population:\n",
    "                if fitness_values_individuals_hist.get(str(genome)) is None:\n",
    "                    fitness_values_individuals_hist[str(genome)] = fitness_func(genome)\n",
    "                fitness_values_individuals.append(fitness_values_individuals_hist[str(genome)])\n",
    "            \n",
    "            fitness_value_population = np.sum(fitness_values_individuals)\n",
    "            k += 1\n",
    "        t += 1\n",
    "    # print(list(zip(population, fitness_values_individuals)))\n",
    "    best_individual = population[np.argmax(fitness_values_individuals)]\n",
    "    return best_individual, fitness_values_individuals[np.argmax(fitness_values_individuals)]\n",
    "\n",
    "x, y = genetic_algorithm()\n",
    "print(f'Best individual: {x}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a36a59aaa9ba51db55ab13fdbe9cb7bf610a761785fc6b04da0d0b9fa4ecb6e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
